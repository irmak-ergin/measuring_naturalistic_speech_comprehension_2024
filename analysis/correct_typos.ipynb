{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e350ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # for punctuation strip\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780dce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the typos on the text summaries\n",
    "df = pd.read_csv('/Users/irmakergin/Desktop/data_all/organized_data_experiment/organized_data.csv')\n",
    "\n",
    "# textblob is not accurate with correcting abbrevations\n",
    "# and  corrects some words inaccurately so I am exclyding them for now.\n",
    "# I am dealing with the abbrevations later in the code before I calculate the semantic similarity\n",
    "\n",
    "exclusion_list = ['ive', 'im', \"i've\", \"i'm\",\n",
    "    \"youre\", \"you're\",\"theyre\", \"they're\", \"shes\", \"she's\",\"hes\", \"he's\",\n",
    "    \"we're\", \"don't\", \"dont\", \"doesn't\", \"doesnt\", \"didn't\", \"didnt\", \n",
    "                  \"sheve\", \"she've\", \"he've\", \"heve\", \"they've\", \"theyve\", \n",
    "                  \"weve\", \"we've\", \"shouldn't\", \"shouldnt\", \"dina\",\"franny\",\n",
    "                  \"frannie\",\"isnt\", \"isn't\",\"aren't\", \"arent\", 'dvd', \"wasnt\", \"wasn't\",\n",
    "                 \"werent\", \"weren't\", \"limo\", \"huh\", \"har\", \"audition\", \"phoney\",\"phony\", \"grilled\", \"robot\",\n",
    "                 \"evertte\", \"mom\", \"caller\", \"memorize\", \"sheila\", 'filming', \"tv\", \"penelope\", \"bagel\",\n",
    "                 \"nanny\", \"candace\",\"giggle\",\"chunky\", \"smouldering\", \"sexy\", \"levine\", \"bunny\",\"barney\",\n",
    "                 \"pants\", \"laundry\", \"kidding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a4c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the abbrevations and turn them into seperate words \n",
    "spelling_changes = {\n",
    "    \"frannie\": [\"franny\"],\n",
    "    \"fanny\": [\"franny\"],\n",
    "    \"ive\": [\"I\", \"have\"],\n",
    "    \"i've\": [\"I\", \"have\"],\n",
    "    \"im\": [\"I\", \"am\"],\n",
    "    \"i'm\": [\"I\", \"am\"],\n",
    "    \"youre\": [\"you\", \"are\"],\n",
    "    \"you're\": [\"you\", \"are\"],\n",
    "    \"theyre\": [\"they\", \"are\"],\n",
    "    \"they're\": [\"they\", \"are\"],\n",
    "    \"shes\": [\"she\", \"is\"],\n",
    "    \"she's\": [\"she\", \"is\"],\n",
    "    \"hes\": [\"he\", \"is\"],\n",
    "    \"he's\": [\"he\", \"is\"],\n",
    "    \"it's\": [\"it\", \"is\"],\n",
    "    \"we're\": [\"we\", \"are\"],\n",
    "    \"don't\": [\"do\", \"not\"],\n",
    "    \"dont\": [\"do\", \"not\"],\n",
    "    \"doesn't\": [\"does\", \"not\"],\n",
    "    \"doesnt\": [\"does\", \"not\"],\n",
    "    \"didn't\": [\"did\", \"not\"],\n",
    "    \"didnt\": [\"did\", \"not\"],\n",
    "    \"sheve\": [\"she\", \"have\"],\n",
    "    \"she've\": [\"she\", \"have\"],\n",
    "    \"he've\": [\"he\", \"have\"],\n",
    "    \"heve\": [\"he\", \"have\"],\n",
    "    \"they've\": [\"they\", \"have\"],\n",
    "    \"theyve\": [\"they\", \"have\"],\n",
    "    \"weve\": [\"we\", \"have\"],\n",
    "    \"we've\": [\"we\", \"have\"],\n",
    "    \"shouldn't\": [\"should\", \"not\"],\n",
    "    \"shouldnt\": [\"should\", \"not\"],\n",
    "    \"isnt\": [\"is\", \"not\"],\n",
    "    \"isn't\": [\"is\", \"not\"],\n",
    "    \"aren't\": [\"are\", \"not\"],\n",
    "    \"arent\": [\"are\", \"not\"],\n",
    "    \"wasnt\": [\"was\", \"not\"], \n",
    "    \"wasn't\": [\"was\", \"not\"],\n",
    "    \"weren't\": [\"were\", \"not\"],\n",
    "    \"werent\": [\"were\", \"not\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e310675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to correct words, excluding words start with capital letter and ones defined above\n",
    "# First correct for \"spelling changes\", then with textblob\n",
    "def preprocess_and_correct_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # Apply spelling changes\n",
    "    words = text.split()\n",
    "    preprocessed_words = []\n",
    "    for word in words:\n",
    "        word_lower = word.lower()\n",
    "        if word_lower in spelling_changes:\n",
    "            # Check if the replacement is a list and extend, otherwise append\n",
    "            if isinstance(spelling_changes[word_lower], list):\n",
    "                preprocessed_words.extend(spelling_changes[word_lower])\n",
    "            else:\n",
    "                preprocessed_words.append(spelling_changes[word_lower])\n",
    "        else:\n",
    "            preprocessed_words.append(word)\n",
    "    preprocessed_text = ' '.join(preprocessed_words)\n",
    "    \n",
    "    # Apply TextBlob corrections, skipping the exclusion list\n",
    "    corrected_words = []\n",
    "    for word in preprocessed_text.split():\n",
    "        if word.lower() not in exclusion_list and not word[0].isupper():\n",
    "            corrected_word = str(TextBlob(word).correct())\n",
    "        else:\n",
    "            corrected_word = word\n",
    "        corrected_words.append(corrected_word)\n",
    "    \n",
    "    return ' '.join(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a3483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['textbox.text_corrected'] = df['textbox.text'].apply(preprocess_and_correct_text)\n",
    "\n",
    "# Change order of columns\n",
    "\n",
    "columns = list(df.columns)\n",
    "\n",
    "# Find the position of 'textbox.text'\n",
    "textbox_text_index = columns.index('textbox.text')\n",
    "\n",
    "# Place 'textbox.text_corrected' right after 'textbox.text'\n",
    "columns.remove('textbox.text_corrected')\n",
    "columns.insert(textbox_text_index + 1, 'textbox.text_corrected')\n",
    "df = df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0bb01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['participant', 'index', 'wav_file', 'old_name', 'duration',\n",
      "       'segment_text', 'question', 'C1', 'C2', 'C3', 'C4', 'C_correct',\n",
      "       'A.numClicks', 'B.numClicks', 'C.numClicks', 'D.numClicks',\n",
      "       'multiple_choice_accuracy', 'likert_response', 'summary',\n",
      "       'textbox.text', 'textbox.text_corrected', 'speech_rate',\n",
      "       'digit_span_score', 'digit_in_noise_score', 'slider_values',\n",
      "       'slider_time', 'slider_values_rescaled', 'slider_values_number',\n",
      "       'trial_movement_score_magnitude', 'movement_score_all',\n",
      "       'likert_rescaled'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      participant  index                      wav_file  \\\n",
       "0            p_1      1   Someday_23_condition-2x.wav   \n",
       "1            p_1      2   Someday_65_condition-2x.wav   \n",
       "2            p_1      3  Someday_123_condition-5x.wav   \n",
       "3            p_1      4   Someday_82_condition-5x.wav   \n",
       "4            p_1      5   Someday_43_condition-4x.wav   \n",
       "...          ...    ...                           ...   \n",
       "2745         p_9    121   Someday_20_condition-4x.wav   \n",
       "2746         p_9    122    Someday_1_condition-2x.wav   \n",
       "2747         p_9    123       Someday_2_condition.wav   \n",
       "2748         p_9    124   Someday_41_condition-4x.wav   \n",
       "2749         p_9    125   Someday_64_condition-2x.wav   \n",
       "\n",
       "                                               old_name   duration  \\\n",
       "0     Someday__Someday__Maybe__Unabridged___File_014...  14.649969   \n",
       "1     Someday__Someday__Maybe__Unabridged___File_032...  14.044969   \n",
       "2     Someday__Someday__Maybe__Unabridged___File_054...   6.032000   \n",
       "3     Someday__Someday__Maybe__Unabridged___File_037...   6.242000   \n",
       "4     Someday__Someday__Maybe__Unabridged___File_023...   7.505000   \n",
       "...                                                 ...        ...   \n",
       "2745  Someday__Someday__Maybe__Unabridged___File_012...   6.865000   \n",
       "2746  Someday__Someday__Maybe__Unabridged___File_004...  14.320000   \n",
       "2747  Someday__Someday__Maybe__Unabridged___File_004...  30.300000   \n",
       "2748  Someday__Someday__Maybe__Unabridged___File_022...   7.205000   \n",
       "2749  Someday__Someday__Maybe__Unabridged___File_031...  14.404969   \n",
       "\n",
       "                                           segment_text  \\\n",
       "0     If you don't have any questions about the mate...   \n",
       "1     From the minute I walk into the wardrobe fitti...   \n",
       "2     I'll admit it's sort of a sick relationship to...   \n",
       "3     The end Huh I say baffled The end is supposed ...   \n",
       "4     Then I'll call my dad and tell him I'm leaving...   \n",
       "...                                                 ...   \n",
       "2745  Upstairs the waiting room is crowded which mea...   \n",
       "2746  It was really more of a gargle I tell myself a...   \n",
       "2747  Successful actresses are disciplined people wh...   \n",
       "2748  And even if I give it more thought and someday...   \n",
       "2749  The traffic isn't too bad yet and the sun is s...   \n",
       "\n",
       "                                               question  \\\n",
       "0     How does the narrator plan to handle the situa...   \n",
       "1     What does the narrator find confusing in the w...   \n",
       "2     Why does Jane call the narrator character ever...   \n",
       "3                             What color are Dan's eyes   \n",
       "4     What does the narrator think her father will s...   \n",
       "...                                                 ...   \n",
       "2745  What observation does the narrator make about ...   \n",
       "2746  What was the actress criticized for during her...   \n",
       "2747  What resolution does the narrator make about h...   \n",
       "2748  What does Penelope say about her rabbit fur ja...   \n",
       "2749                  What is happening on 72nd Street?   \n",
       "\n",
       "                                                     C1  \\\n",
       "0                     A. By making small talk and jokes   \n",
       "1                       A. The lack of clothing options   \n",
       "2                                    A. To share gossip   \n",
       "3                             A. Blue with green flecks   \n",
       "4                  A. That she is doing the right thing   \n",
       "...                                                 ...   \n",
       "2745  A. They are all likely there for the same cast...   \n",
       "2746                             A. Laughing too loudly   \n",
       "2747         A. To wake up early and focus on her craft   \n",
       "2748                                       A. It's fake   \n",
       "2749                                   A. A traffic jam   \n",
       "\n",
       "                                                     C2  \\\n",
       "0              B. By panicking and asking for more time   \n",
       "1                         B. The number of people there   \n",
       "2            B. To check if the main character is awake   \n",
       "3                                         B. Deep brown   \n",
       "4                  B. That she should have tried harder   \n",
       "...                                                 ...   \n",
       "2745              B. They are unorganized and scattered   \n",
       "2746                    B. Belching during the dialogue   \n",
       "2747  B. To quit smoking and stop losing personal items   \n",
       "2748                                    B. It's vintage   \n",
       "2749                                    B. A film shoot   \n",
       "\n",
       "                                                     C3  ... speech_rate  \\\n",
       "0                    C. By admitting she didn't prepare  ...           2   \n",
       "1                    C. The presence of a harried woman  ...           2   \n",
       "2                 C. To discuss their favorite TV shows  ...           5   \n",
       "3                            C. Brown with green flecks  ...           5   \n",
       "4     C. That she can go back to New York if she wan...  ...           4   \n",
       "...                                                 ...  ...         ...   \n",
       "2745  C. They appear to be different versions of the...  ...           4   \n",
       "2746                            C. Forgetting her lines  ...           2   \n",
       "2747  C. To stop eating cheese puffs, even on specia...  ...           1   \n",
       "2748                                 C. It's for Easter  ...           4   \n",
       "2749                                        C. A parade  ...           2   \n",
       "\n",
       "     digit_span_score  digit_in_noise_score  \\\n",
       "0                  20                    60   \n",
       "1                  20                    60   \n",
       "2                  20                    60   \n",
       "3                  20                    60   \n",
       "4                  20                    60   \n",
       "...               ...                   ...   \n",
       "2745               23                    80   \n",
       "2746               23                    80   \n",
       "2747               23                    80   \n",
       "2748               23                    80   \n",
       "2749               23                    80   \n",
       "\n",
       "                                          slider_values  \\\n",
       "0     0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "1     0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "2     0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "3     0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "4     0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "...                                                 ...   \n",
       "2745  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "2746  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "2747  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "2748  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "2749  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "\n",
       "                                            slider_time  \\\n",
       "0     4.02,8.02,12.02,16.02,20.02,24.02,28.02,32.02,...   \n",
       "1     4.02,8.02,12.02,16.02,20.02,24.02,28.02,32.02,...   \n",
       "2     4.03,8.03,12.03,16.03,20.03,24.03,28.03,32.03,...   \n",
       "3     3.94,7.94,11.94,15.94,19.94,23.94,27.94,31.94,...   \n",
       "4     3.97,7.97,11.97,15.97,19.97,23.97,27.97,31.97,...   \n",
       "...                                                 ...   \n",
       "2745  3.97,7.97,11.97,15.97,19.97,23.97,27.97,31.97,...   \n",
       "2746  3.95,7.95,11.95,15.95,19.95,23.95,27.95,31.95,...   \n",
       "2747  3.94,7.94,11.94,15.94,19.94,23.94,27.94,31.94,...   \n",
       "2748  3.94,7.94,11.94,15.94,19.94,23.94,27.94,31.94,...   \n",
       "2749  3.96,7.96,11.96,15.96,19.96,23.96,27.96,31.96,...   \n",
       "\n",
       "                                 slider_values_rescaled  slider_values_number  \\\n",
       "0     0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                  3669   \n",
       "1     0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                  3515   \n",
       "2     0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                  1511   \n",
       "3     0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                  1565   \n",
       "4     0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                  1880   \n",
       "...                                                 ...                   ...   \n",
       "2745  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                  1722   \n",
       "2746  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                  3590   \n",
       "2747  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                  7587   \n",
       "2748  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                  1809   \n",
       "2749  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...                  3608   \n",
       "\n",
       "      trial_movement_score_magnitude movement_score_all likert_rescaled  \n",
       "0                              487.0              41150        0.995000  \n",
       "1                              255.0              41150        1.000000  \n",
       "2                              244.0              41150        0.130833  \n",
       "3                              340.0              41150        0.116667  \n",
       "4                              515.0              41150        0.205000  \n",
       "...                              ...                ...             ...  \n",
       "2745                           118.0              35841        0.296667  \n",
       "2746                           263.0              35841        1.000000  \n",
       "2747                           255.0              35841        1.000000  \n",
       "2748                            25.0              35841        0.135833  \n",
       "2749                           285.0              35841        1.000000  \n",
       "\n",
       "[2750 rows x 31 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef506ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add empty column to enter manual corrections\n",
    "# Find the index of 'textbox.text_corrected' column\n",
    "corrected_text_index = df.columns.get_loc('textbox.text_corrected') + 1\n",
    "\n",
    "# Insert the new empty column 'textbox.text_corrected_manual' right after 'textbox.text_corrected'\n",
    "df.insert(corrected_text_index, 'textbox.text_corrected_manual', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7bc7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['participant', 'index', 'wav_file', 'old_name', 'duration',\n",
      "       'segment_text', 'question', 'C1', 'C2', 'C3', 'C4', 'C_correct',\n",
      "       'A.numClicks', 'B.numClicks', 'C.numClicks', 'D.numClicks',\n",
      "       'multiple_choice_accuracy', 'likert_response', 'summary',\n",
      "       'textbox.text', 'textbox.text_corrected',\n",
      "       'textbox.text_corrected_manual', 'speech_rate', 'digit_span_score',\n",
      "       'digit_in_noise_score', 'slider_values', 'slider_time',\n",
      "       'slider_values_rescaled', 'slider_values_number',\n",
      "       'trial_movement_score_magnitude', 'movement_score_all',\n",
      "       'likert_rescaled'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d873f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "df.to_csv('/Users/irmakergin/Desktop/data_all/organized_data_experiment/organized_data_no_typo.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mne]",
   "language": "python",
   "name": "conda-env-mne-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
