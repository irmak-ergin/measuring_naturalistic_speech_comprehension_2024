
```{r}
# Load libraries
library(stringr)
library(fs)
library(dplyr)
library(readxl)
library(readr)
library(simr)
library(lmerTest)
library(patchwork)
library(RColorBrewer)
library(cowplot)
library(ggplot2)
library(tidyr) 
library(purrr)
library(scales)

# set the default ggplot theme 
theme_set(theme_classic())
```

```{r}
# Set path and participant ids

# Change the folder path to final-project-irmak-ergin/data relative to your wd
folder_path <- '/Users/irmakergin/Desktop/final-project-irmak-ergin/data_sum'

# Define the list of participant IDs
participant_ids <- c("p_1", "p_2","p_3")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Organize the data csv files

# Get a list of all files in the folder
files <- dir(folder_path, full.names = TRUE)

# Set a path to save the organized files
organized_data_path<-"/Users/irmakergin/Desktop/final-project-irmak-ergin/organized_data_sum"


# Find files by participant ID 
for(part_id in participant_ids) {

  # Match the slider files that involve the participant ID
  slider_pattern <- paste0("slider_", part_id, ".*\\.csv$")
  
  # Match data (csv) files that start with the participant ID
  additional_csv_pattern <- paste0("^", part_id, "_.*\\.csv$")
  
  # Find slider files that match the pattern
  slider_matched_files <- files[str_detect(basename(files), slider_pattern)]
  
  # Find data CSV files that match the pattern
  additional_csv_matched_files <- files[str_detect(basename(files), 
                                                   additional_csv_pattern)]
   
  # Create a directory for the current participant on the organized data path
  participant_folder <- file.path(organized_data_path, part_id)
  if(!dir.exists(participant_folder)) {
    dir.create(participant_folder, recursive = TRUE, showWarnings = TRUE)
  }
  
  # Create a subdirectory for slider files within the participant folder
  slider_folder <- file.path(participant_folder, paste0("slider_", part_id))
  if(!dir.exists(slider_folder)) {
    dir.create(slider_folder, recursive = TRUE, showWarnings = TRUE)
  }
  
  # Move slider matched files to the slider subfolder
  if(length(slider_matched_files) > 0) {
    for(file in slider_matched_files) {
      file_copy(file, file.path(slider_folder, basename(file)), overwrite = TRUE)
    }
  }
  
  # Move additional CSV matched files (experiment data) to the main participant folder 
  #and rename the participant folders
  if(length(additional_csv_matched_files) > 0) {
  # loop to rename the file during the copy process
  for(file in additional_csv_matched_files) {
    # New filename with '_raw_data'
    new_name <- paste0(part_id, "_raw_data.csv")
    # Copy and rename the file to the new name in the participant folder
    file_copy(file, file.path(participant_folder, new_name), overwrite = TRUE)
  }
}
  # check
  if(length(slider_matched_files) > 0 || length(additional_csv_matched_files) > 0) {
    cat("Files for participant ID '", part_id, 
        "' have been organized successfully. Slider files in: ", slider_folder, 
        ", other CSVs in: ", participant_folder, "\n")
  } else {
    cat("No files found for participant ID '", part_id, "'.\n")
  }
}

# Put excel files (of digit in noise and digit span) in the organized data folder 

source_folder<-"/Users/irmakergin/Desktop/final-project-irmak-ergin/data_sum"
destination_folder<-"/Users/irmakergin/Desktop/final-project-irmak-ergin/organized_data_sum"

# List all Excel files in the source folder
excel_files <- dir_ls(path = source_folder, glob = "*.xlsx")

# Copy each Excel file to the destination folder- commented out to re-run
#for (file_path in excel_files) {
#dest_file_path <- file.path(destination_folder, path_file(file_path))
#file_copy(file_path, dest_file_path)
#   
 #Check
#cat("Copied:", file_path, "to", dest_file_path, "\n")
#}

# Loop through each participant ID
for (part_id in participant_ids) {
  # Define the path to the participant's raw data CSV
  raw_data_path <- file.path(organized_data_path, 
                             part_id, 
                             paste0(part_id, "_raw_data.csv"))
 # Read the CSV for each participant (if it exists)
  if (file.exists(raw_data_path)) {
  df.raw <- read_csv(raw_data_path) %>%
    filter(!wav_file %in% c("Someday_trial_condition.wav", 
                            "Someday_trial_condition-4x.wav")) %>%
    mutate(index = row_number()) %>%
    select(index, participant, wav_file, old_name, segment_text, duration,
           `Summary.started` ,`Summary.stopped`,`Experimen_audio.started`, 
           `textbox.text`) %>%
    group_by(wav_file) %>%
    summarise(
      index = first(index), 
      participant = first(participant), 
      old_name = first(old_name),
      segment_text = first(segment_text),
      duration = first(duration),
      summary_start= first(Summary.started),
      summary_stop= first(Summary.stopped),
      textbox.text = first(textbox.text),
      .groups = 'drop'
    ) %>%
    arrange(index) %>%
    mutate(index = row_number()) 
  
  # Fill NA values in participant_id column with part_id for participant p_1
    if (part_id == "p_1") {
      df.raw <- df.raw %>%
        mutate(participant = replace_na(participant, part_id))
    }

   # Remove the extra last row from df.raw
    df.raw <- head(df.raw, n = -1)
    
  # Assign processed data of each participant to a new df
  assign(paste0("df.raw.merged_", part_id), df.raw, envir = .GlobalEnv)
  }
}
# Sanity check
# how many rows do we have- should be 150
nrow(df.raw.merged_p_3)

```

```{r}
# Merge all participant dfs into one df

# Create an empty data frame to store merged data
df.raw <- data.frame()

# Loop through each participant ID and merge their df
for (part_id in participant_ids) {
  # Construct the name of the data frame variable
  df_name <- paste0("df.raw.merged_", part_id)
  
  # Check if the data frame exists in the global environment
  if (exists(df_name, envir = .GlobalEnv)) {
    # Get the data frame from its name
    df_participant <- get(df_name, envir = .GlobalEnv)
    
    # Merge the data frame with the main merged data frame
    df.raw <- rbind(df.raw, df_participant)
  }
}
```

```{r}
# Extract the speech rate information from the trial name and create a speech_rate column
df.raw<- df.raw %>%
  mutate(speech_rate = case_when(
    str_detect(wav_file, "2x") ~ 2,
    str_detect(wav_file, "3x") ~ 3,
    str_detect(wav_file, "4x") ~ 4,
    str_detect(wav_file, "5x") ~ 5,
    TRUE ~ 1  # not sped up if there are no numbers + x in the name 
  ))
```

```{r}
# calculate the summary duration and add it as a new column
df.raw$summary_duration <- as.numeric(df.raw$summary_stop) - as.numeric(df.raw$summary_start)
```

```{r}
# Add the Digit Span (working memory) scores of each participant

# Create an empty digit_span_score column
df.raw$digit_span_score <- NA

for (part_id in unique(df.raw$participant)) {
  # Construct the filename based on the participant ID
  filename <- paste0(organized_data_path, "/digit_span_summary_", part_id, ".xlsx")
  
  # Check if the file exists
  if (file.exists(filename)) {
    # Correctly read the file using read_excel
    digit_span_data <- read_excel(filename)
    
    # Assuming the score is located in the first row of the 'score' column
    score <- digit_span_data$score[1]
      
    # Now this should work since digit_span_score column exists
    df.raw<- df.raw%>%
      mutate(digit_span_score = ifelse(participant == part_id, score, digit_span_score))
  } else {
    cat("File not found for participant", part_id, "\n")
  }
}
```

```{r, warning= FALSE, message=FALSE}

# Add the hearWHO (digit-in-noise task for hearing in noise) scores of each participants

hearwho_pilot_data <- read_excel(paste0(organized_data_path,
                                        "/hearwho_pilot_summary.xlsx"))

# Excel file has columns named 'participant' and 'score'
# Merge the scores into df.raw based on participant ID
df.raw <- merge(df.raw, hearwho_pilot_data[, c("participant", "score")], 
                       by.x = "participant", by.y = "participant", all.x = TRUE)

# Rename the 'score' column to 'digit_in_noise_score'
names(df.raw)[names(df.raw) == "score"] <- "digit_in_noise_score"
```

```{r}
# Add slider values

# Find the slider values for each trial and save them to the df
participants <- unique(df.raw$participant)

# Add a new column for slider values 
if (!"slider_values" %in% names(df.raw)) {
  df.raw$slider_values <- NA
}

# Define a function to extract and return slider values as a string
get_slider_values <- function(wav_file_name, part_id) {
  # Extract the trial number from wav_file name
  matches <- regmatches(wav_file_name, regexec("Someday_([0-9]+)", wav_file_name))
  if (length(matches[[1]]) < 2) { # If no match or match does not have a capture group
    return(NA)
  }
  trial_number <- matches[[1]][2]

  # Construct the path to the slider file
  slider_file_path <- sprintf("%s/%s/slider_%s/*_%s_*.csv", 
                              organized_data_path, 
                              part_id, part_id, 
                              trial_number)

  # Find slider files matching the pattern
  slider_files <- Sys.glob(slider_file_path)
  
  if (length(slider_files) == 0) {
    return(NA) # No matching file found
  }
  
  slider_data <- read.csv(slider_files[1], skip = 1)

  if ("value" %in% colnames(slider_data)) {
    # Concatenate slider values into a string
    return(paste(slider_data$value, collapse = ","))
  } else {
    return(NA)
  }
}

# Apply the function to each row of df.raw.merged
df.raw$slider_values <- mapply(get_slider_values, 
                                      df.raw$wav_file, 
                                      df.raw$participant)
```

```{r}
# correct for slider value= participant id

participant_name <- "p_1" 
wav_file_name <- "Someday_1_condition-2x.wav"
file_path_name <- paste0(organized_data_path, "/", 
                         "p_1/slider_p_1/slider_p_1_001_Someday_1_condition-2x.wav.csv")

# Read the specified file
slider_data <- read.csv(file_path_name, skip = 1)

# Concatenate slider values into a string
slider_values_str <- paste(slider_data$value, collapse = ",")

# Count the number of slider values
slider_values_count <- length(slider_data$value)
cat("Number of slider values:", slider_values_count, "\n")

# Update the df.raw dataframe with the new slider values 
df.raw <- df.raw %>%
  mutate(slider_values=ifelse(participant == participant_name & wav_file == wav_file_name, 
                                slider_values_str, slider_values))

participant_name <- "p_2" 
wav_file_name <- "Someday_2_condition-3x.wav" 
file_path_name <- paste0(organized_data_path, "/", 
                         "p_2/slider_p_2/slider_p_2_001_Someday_2_condition-3x.wav.csv")

# Read the specified file
slider_data <- read.csv(file_path_name, skip = 1)

# Concatenate slider values into a string
slider_values_str <- paste(slider_data$value, collapse = ",")

# Count the number of slider values
slider_values_count <- length(slider_data$value)
cat("Number of slider values:", slider_values_count, "\n")

# Update the df.raw dataframe with the new slider values 
df.raw <- df.raw %>%
  mutate(slider_values=ifelse(participant == participant_name & wav_file == wav_file_name, 
                                slider_values_str, slider_values))

participant_name <- "p_3" 
wav_file_name <- "Someday_3_condition-4x.wav" 
file_path_name <- paste0(organized_data_path, "/", 
                         "p_3/slider_p_3/slider_p_3_001_Someday_3_condition-4x.wav.csv")

# Read the specified file
slider_data <- read.csv(file_path_name, skip = 1)

# Concatenate slider values into a string
slider_values_str <- paste(slider_data$value, collapse = ",")

# Count the number of slider values
slider_values_count <- length(slider_data$value)
cat("Number of slider values:", slider_values_count, "\n")

# Update the df.raw dataframe with the new slider values 
df.raw <- df.raw %>%
  mutate(slider_values=ifelse(participant == participant_name & wav_file == wav_file_name, 
                                slider_values_str, slider_values))

```

```{r}
# Rescale slider values to be between 0-1

# Convert slider_values from string to numeric lists 
df.raw$slider_values <- strsplit(as.character(df.raw$slider_values), 
                                        ",\\s*")
df.raw$slider_values <- lapply(df.raw$slider_values, 
                                      function(x) as.numeric(x))

rescale_values <- function(values) {
  sapply(values, function(x) x / 255)
}

# Apply the rescaling function to each row's slider_values
df.raw$slider_values_rescaled <- lapply(df.raw$slider_values, 
                                               rescale_values)
```

```{r}
# Sanity check: create a column showing number of slider values
df.raw <- df.raw %>%
  mutate(slider_values_number = lengths(slider_values_rescaled))
```

```{r, warning=FALSE}
# Depict slider movements 

df.raw$slider_values_rescaled <- sapply(df.raw$slider_values_rescaled, 
                                               function(x) paste(x, collapse = ","))

df.slider <- df.raw%>%
  mutate(slider_values_rescaled = strsplit(slider_values_rescaled, ",")) %>%
  mutate(slider_rescale_float = map(slider_values_rescaled, ~as.numeric(.x)))

df_long <- df.slider %>%
  mutate(id = row_number()) %>%
  unnest(slider_rescale_float) %>%
  rename(slider_value = slider_rescale_float) %>%
  group_by(id, speech_rate) %>%
  mutate(index = row_number()) %>%
  ungroup() %>%
  select(-slider_values_rescaled)

# Set the x-axis limits 
p_slider_per_rate <- ggplot(df_long, aes(x = index, 
                                         y = slider_value, 
                                         group = interaction(id), 
                                         color = as.factor(id))) +
  geom_line(alpha = 0.5, size = 0.5) +
  scale_x_continuous(name = "Index of the Slider Value") +
  scale_y_continuous(name = "Slider Value") +
  facet_wrap(~ speech_rate, 
             scales = 'free_x', 
             ncol = 1) +
  scale_color_manual(values = colorRampPalette(brewer.pal(12, "Paired"))
                     (length(unique(df_long$id)))) +
  theme(legend.position = "none") +
  labs(title = 'Slider Values by Speech Rate',
      caption = "Each line represents the comprehension trajectory at different speech rates.
      As the speech rate increases, comprehension scores seem to get lower."
)

# histograms 

p_flipped_histogram_per_rate <- ggplot(df_long, aes(x = slider_value)) +
  geom_histogram(bins = 10, fill = "skyblue", color = "navy") +
  coord_flip() +
  facet_wrap(~speech_rate, scales = 'free_x', ncol = 1) +
  labs(y = "Slider Value Range", x = "Count", title = "Number of Slider Values by Speech Rate") +
  theme(legend.position = "none") +
  scale_y_continuous(labels = comma) 

# combine
combined_plot <- p_slider_per_rate + p_flipped_histogram_per_rate + 
  plot_layout(ncol = 2, widths = c(2, 1)) +
  theme(strip.background = element_rect(fill = "white", color = "black"))
  


print(combined_plot)

```

```{r}
# Sanity check for slider values 

rows_not_fitting_criteria_selected_columns <- df.raw %>%
  filter(
    (speech_rate == 1 & (slider_values_number < 6000 | slider_values_number > 8000)) |
    (speech_rate == 2 & (slider_values_number < 3000 | slider_values_number > 4000)) |
    (speech_rate == 2.5 & (slider_values_number < 3000 | slider_values_number > 3500)) |
    (speech_rate == 3 & (slider_values_number < 2500 | slider_values_number > 3000)) |
    (speech_rate == 3.5 & (slider_values_number < 2000 | slider_values_number > 2500)) |
    (speech_rate == 4 & (slider_values_number < 1500 | slider_values_number > 2000))
  ) %>%
  select(participant, wav_file, index, slider_values_number)

# To print the resulting selected columns for rows that do not fit the criteria
print(rows_not_fitting_criteria_selected_columns)

# manually inspect those to see if they are just sampled slightly longer/ shorter or if the match is wrong
```
Manually checked- All good!

```{r}
# Calculate the average summary_duration per speech_rate for each participant
avg_duration_per_speech_rate <- df.raw %>%
  group_by(participant, speech_rate) %>%
  summarise(average_summary_duration = mean(summary_duration, na.rm = TRUE)) %>%
  ungroup()

# Ensure speech_rate and participant are treated as factors
avg_duration_per_speech_rate$speech_rate <- factor(avg_duration_per_speech_rate$speech_rate)
avg_duration_per_speech_rate$participant <- factor(avg_duration_per_speech_rate$participant)

# Plot
ggplot(avg_duration_per_speech_rate, aes(x = speech_rate, y = average_summary_duration, fill = speech_rate)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.75)) +
  geom_text(aes(label = sprintf("%.2f", average_summary_duration)), 
            position = position_dodge(width = 0.75), vjust = -0.25, color = "black", size = 3.5) +
  facet_wrap(~ participant, scales = "free_y", nrow = 1) +
  theme_classic() + 
  labs(title = "Average Summary Duration by Speech Rate for Each Participant",
       x = "Speech Rate",
       y = "Average Summary Duration (seconds)") +
  scale_fill_brewer(palette = "Pastel1", type = "qual") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")

  

```

```{r}
# Create the faceted line plot of summary time for each participant and speech rate

# Get a list of unique participants
participants <- unique(df.raw$participant)

# Loop through each participant to create and print a plot
for (part_id in participants) {
  # Filter the data for the current participant
  df.part <- filter(df.raw, participant == part_id)
  
  # Create the plot for the current participant
  p <- ggplot(df.part, aes(x = index, y = summary_duration)) +
    geom_line() + # Draw lines
    facet_wrap(~ speech_rate, scales = "free_y", ncol = 3) + # Facet column numbers
    theme_minimal() +
    labs(title = paste("Summary Duration for Participant", part_id, "by Speech Rate"),
         x = "Trial Index",
         y = "Summary Duration (second)") +
    theme(strip.text.x = element_text(size = 8)) # Adjust the facet label text size 
  
  print(p) # Print the plot
}
```

```{r}
# total time spent on writing

# Summarize total duration in minutes for each participant
total_duration_per_participant <- df.raw %>%
  group_by(participant) %>%
  summarise(total_duration_minutes = sum(summary_duration, na.rm = TRUE) / 60) %>%
  ungroup()

# Print the total duration in minutes for each participant
total_duration_per_participant
```

```{r}
# median duration for each speech rate per participant

# Group the data by participant and speech rate, then calculate the median summary duration
median_summary_duration <- df.raw %>%
  group_by(participant, speech_rate) %>%
  summarize(median_duration = median(summary_duration, na.rm = TRUE), .groups = 'drop')

# Check the resulting data frame to make sure it looks correct
print(median_summary_duration)

# median duration for each speech rate across participants

median_summary_duration_all <- df.raw %>%
  group_by(speech_rate) %>%
  summarize(median_duration = median(summary_duration, na.rm = TRUE), .groups = 'drop')

print(median_summary_duration_all)
```

```{r}
# sanity check- per participant
# Directly create the unique identifier for each speech_rate-participant_id combination without converting to factors first
df.group <- df.raw %>%
  mutate(group_id = interaction(speech_rate, participant))%>%
  select(group_id, summary_duration)

# Now split the dataframe into a list of dataframes based on the group_id
list_of_dfs <- split(df.group, f = df.group$group_id)

# Iterate over each dataframe in the list to add the summary_median column
list_of_dfs_with_median <- lapply(list_of_dfs, function(df) {
  median_value <- median(df$summary_duration, na.rm = TRUE)  # Calculate the median of summary_duration
  df$summary_median <- median_value  # Add the median as a new column
  return(df)
})

# Check the first dataframe in the list to confirm the summary_median column has been added
head(list_of_dfs_with_median[[18]])
```
```{r}
#sanity check per speech rate
# Directly create the unique identifier for each speech_rate
df.group <- df.raw %>%
  mutate(group_id = speech_rate)%>%
  select(group_id, summary_duration)

# Now split the dataframe into a list of dataframes based on the group_id
list_of_dfs <- split(df.group, f = df.group$group_id)

# Iterate over each dataframe in the list to add the summary_median column
list_of_dfs_with_median <- lapply(list_of_dfs, function(df) {
  median_value <- median(df$summary_duration, na.rm = TRUE)  # Calculate the median of summary_duration
  df$summary_median <- median_value  # Add the median as a new column
  return(df)
})

```


```{r}
# Exclude the first 8 trials for each speech_rate for each participant
df.filtered <- df.raw %>%
  group_by(participant, speech_rate) %>%
  mutate(trial_rank = row_number()) %>%
  filter(trial_rank > 8) %>%
  ungroup()

# Calculate the average summary_duration for each speech_rate for each participant
df.avg <- df.filtered %>%
  group_by(participant, speech_rate) %>%
  summarise(average_duration = mean(summary_duration, na.rm = TRUE)) %>%
  ungroup() # Ensure speech_rate is treated as a factor
df.avg$speech_rate <- as.factor(df.avg$speech_rate)

# Create the faceted bar plot for each participant
ggplot(df.avg, aes(x = speech_rate, y = average_duration, fill = speech_rate)) +
  geom_bar(stat = "identity", color = "black") +
  facet_wrap(~ participant, scales = "free_y", nrow = 1) + # Adjust number of rows as needed
  scale_fill_brewer(palette = "Pastel1") + # Apply Pastel1 colors
  theme_classic() +
  labs(title = "Average Summary Duration by Speech Rate for Each Participant 
       (Excluding First 8 Trials)",
       x = "Speech Rate",
       y = "Average Summary Duration (second)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none") 
```
change the pathway:
```{r}
# save the data and calculate semantic similarity score 

# Convert list to string for slider values
df.raw$slider_values <- sapply(df.raw$slider_values, 
                                      function(x) paste(x, collapse = ","))

write.csv(df.raw, file = "/Users/irmakergin/Desktop/df_raw.csv", row.names = FALSE)
```

```{r}
# load the sem similarity score data
# Load the csv file into R as a dataset named df.data
df.data <- read.csv("/Users/irmakergin/Desktop/df_raw_similarity.csv")

```

```{r}
# plot sem similarity per speech rate
average_similarity <- df.data %>%
  group_by(speech_rate) %>%
  summarise(average_similarity = mean(sum_max_similarity, na.rm = TRUE))

# Plot with bars in light green
ggplot(average_similarity, aes(x = factor(speech_rate), y = average_similarity, fill = as.factor(speech_rate))) +
  geom_bar(stat = "identity", position = "dodge", fill = "darkseagreen1") + 
  labs(x = "Speech Rate", y = "Average Sum Max Similarity", 
       title = "Average Sum Max Similarity by Speech Rate") +
  geom_text(aes(label = round(average_similarity, 2)), 
            vjust = -0.3, position = position_dodge(width = 0.9), size = 3) +
  theme(legend.position = "none")
```

```{r}
# plot sem similarity per speech rate per participant
average_similarity <- df.data %>%
  group_by(participant, speech_rate) %>%
  summarise(average_similarity = mean(sum_max_similarity, na.rm = TRUE), .groups = 'drop')

# Plot with bars in light green and facet by participant
average_similarity_participant<- ggplot(average_similarity, aes(x = factor(speech_rate), y = average_similarity, fill = as.factor(speech_rate))) +
  geom_bar(stat = "identity", position = "dodge", fill = "darkseagreen1") +
  facet_wrap(~participant, ncol = 3) +  # Faceted by participant
  labs(x = "Speech Rate", y = "Average Sum Max Similarity", 
       title = "Average Sum Max Similarity by Participant and Speech Rate") +
  geom_text(aes(label = round(average_similarity, 2)), 
            vjust = -0.3, position = position_dodge(width = 0.9), size = 3) +
  theme(legend.position = "none")
print (average_similarity_participant)

```

```{r}
#What about the number of words they reported regardless of the semantic similarity of the words?

# Calculate the number of words
df.data <- df.data %>%
  mutate(word_count = str_count(textbox.text_corrected, "\\S+") + 1)

# Aggregate data by speech rate
aggregated_data <- df.data %>%
  group_by(speech_rate) %>%
  summarize(avg_word_count = mean(word_count, na.rm = TRUE),
            .groups = 'drop')

# Plot
ggplot(aggregated_data, aes(x = as.factor(speech_rate), y = avg_word_count, 
                            fill = as.factor(speech_rate))) +
  geom_bar(stat = "identity" , position = "dodge", fill = "darkseagreen3") + 
  geom_text(aes(label = sprintf("%.2f", avg_word_count)), vjust = -0.5, color = "black") +
  labs(title = "Average Number of Words Reported Across Speech Rates",
       x = "Speech Rate",
       y = "Average Word Count",
       fill = "Speech Rate") +
  theme(legend.position = "none")
```

```{r}
# number of words for each speech rate per participant

# Calculate the number of words
df.data <- df.data %>%
  mutate(word_count = str_count(textbox.text_corrected, "\\S+") + 1)

# Aggregate data by participant and speech rate
aggregated_data <- df.data %>%
  group_by(participant, speech_rate) %>%
  summarize(avg_word_count = mean(word_count, na.rm = TRUE),
            .groups = 'drop')

# Plot with faceting by participant
plot_num_words_part <- ggplot(aggregated_data, aes(x = as.factor(speech_rate), y = avg_word_count, 
                            fill = as.factor(speech_rate))) +
  geom_bar(stat = "identity", position = "dodge", fill = "darkseagreen3") + 
  geom_text(aes(label = sprintf("%.2f", avg_word_count)), 
            vjust = -0.5, color = "black", position = position_dodge(width = 0.9)) +
  labs(title = "Average Number of Words Reported Across Speech Rates",
       x = "Speech Rate",
       y = "Average Word Count",
       fill = "Speech Rate") +
  facet_wrap(~participant, ncol = 3, scales = "free_y") +
  theme(legend.position = "none")

# Run the plot
print(plot_num_words_part)

```
Now let's do all these with sentence embedding rather than word embedding:
```{r}
# plot sem similarity for sentence embedding per speech rate
average_similarity_sent <- df.data %>%
  group_by(speech_rate) %>%
  summarise(average_similarity_sent = mean(cosine_similarity, na.rm = TRUE))

# Plot with bars in light green
ggplot(average_similarity_sent, aes(x = factor(speech_rate), y = average_similarity_sent, fill = as.factor(speech_rate))) +
  geom_bar(stat = "identity", position = "dodge", fill = "darkseagreen1") + 
  labs(x = "Speech Rate", y = "Average Sentence Embedding Similarity", 
       title = "Average Cosine Similarity by Speech Rate") +
  geom_text(aes(label = round(average_similarity_sent, 2)), 
            vjust = -0.3, position = position_dodge(width = 0.9), size = 3) +
  theme(legend.position = "none")
```
???

```{r}
# per participant

# Assuming df.data is your data frame and it includes a 'participant' column
average_similarity_sent_participant <- df.data %>%
  group_by(participant, speech_rate) %>%
  summarise(average_similarity_sent = mean(cosine_similarity, na.rm = TRUE)) %>%
  ungroup()

# Plot with bars, faceted per participant
ggplot(average_similarity_sent_participant, aes(x = factor(speech_rate), y = average_similarity_sent, fill = as.factor(speech_rate))) +
  geom_bar(stat = "identity", position = "dodge", fill = "darkseagreen1") + 
  labs(x = "Speech Rate", y = "Average Sentence Embedding Similarity",
       title = "Average Cosine Similarity by Speech Rate and Participant") +
  geom_text(aes(label = round(average_similarity_sent, 2)), vjust = -0.3, position = position_dodge(width = 0.9), size = 3) +
  theme(legend.position = "none") +
  facet_wrap(~participant, ncol = 5) # Adjust the number of columns based on the number of participants
```
Stimulinin her cumlesini ayirip olarin tek tek summryle simialritysine bakip maxini alabilirsin?


Check the semantic similarity by sampling 12 random trials for each participant for each speech rate. 

```{r}
df.twelf <- df.data %>%
  group_by(participant, speech_rate) %>%
  slice_sample(n = 12, replace = TRUE) %>%
  ungroup()

# Calculate the average similarity per speech rate for each participant
avg_similarity_per_participant <- df.twelf %>%
  group_by(participant, speech_rate) %>%
  summarise(average_similarity = mean(sum_max_similarity, na.rm = TRUE), .groups = 'drop')

# Calculate the overall average similarity per speech rate across all participants
overall_avg_similarity <- df.twelf %>%
  group_by(speech_rate) %>%
  summarise(participant = "All",  # Create an "All" participant category
            average_similarity = mean(sum_max_similarity, na.rm = TRUE), .groups = 'drop')

# Combine the two datasets
combined_similarity <- bind_rows(avg_similarity_per_participant, overall_avg_similarity)

# Ensure speech_rate and participant are treated as factors
combined_similarity$speech_rate <- factor(combined_similarity$speech_rate)
combined_similarity$participant <- factor(combined_similarity$participant, 
                                          levels = c("All", unique(df.twelf$participant)))

# Plot with facets for each participant including an "All" category
combined_similarity_plot <- ggplot(combined_similarity, aes(x = speech_rate, y = average_similarity, fill = speech_rate)) +
  geom_bar(stat = "identity", position = "dodge", fill = "lightpink") +
  facet_wrap(~ participant, ncol = 4) + # Assuming 3 participants + "All" category
  labs(x = "Speech Rate", y = "Average Sum Max Similarity",
       title = "Average Sum Max Similarity by Speech Rate and Participant") +
  geom_text(aes(label = round(average_similarity, 2)), 
            vjust = -0.3, position = position_dodge(width = 0.9), size = 3) +
  theme(legend.position = "none", 
        strip.background = element_rect(fill = "white", color = "black"),
        strip.text = element_text(face = "bold"))

# Display the plot
print(combined_similarity_plot)

```




