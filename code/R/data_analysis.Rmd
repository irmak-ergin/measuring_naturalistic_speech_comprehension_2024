title: "Measuring Naturalistic Speech Comprehension in Real Time"
author: "Irmak Ergin, Jill Kries, Shiven Gupta, Laura Gwilliams"
date: "`r Sys.time()`"
urlcolor: blue # to show hyperlinks in blue when printed as pdf

# uncomment below to render to html
# output:
#   bookdown::html_document2:
#     toc: true
#     toc_depth: 4
#     theme: cosmo
#     highlight: tango
    
# uncomment below to render to pdf
output:
  bookdown::pdf_book:
    toc: true
    toc_depth: 4
    highlight: tango

bibliography: [references/packages.bib, references/references.bib]
biblio-style: apalike
nocite: '@*'
---

# Data Wrangling

```{r setup, echo=FALSE, message=FALSE}
# Load libraries
library(stringr)
library(fs)
library(dplyr)
library(readxl)
library(readr)
library(simr)
library(lmerTest)
library(patchwork)
library(RColorBrewer)
library(cowplot)
library(ggplot2)
library(tidyr) 
library(purrr)
library(scales)
library(gridExtra)

# set the default ggplot theme 
theme_set(theme_classic())
```

```{r}
# Set path and participant ids

# Change the folder path to final-project-irmak-ergin/data relative to your wd
folder_path <- '/Users/irmakergin/Desktop/2023_speech_rate/data_experiment'

# Define the list of participant IDs
participant_ids <- c("p_1","p_2","p_3","p_4","p_5", "p_6", "p_7", "p_8", "p_9")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Organize the data csv files

# Get a list of all files in the folder
files <- dir(folder_path, full.names = TRUE)

# Set a path to save the organized files
organized_data_path<-"/Users/irmakergin/Desktop/2023_speech_rate/organized_data_experiment"


# Find files by participant ID 
for(part_id in participant_ids) {

  # Match the slider files that involve the participant ID
  slider_pattern <- paste0("slider_", part_id, ".*\\.csv$")
  
  # Match data (csv) files that start with the participant ID
  additional_csv_pattern <- paste0("^", part_id, "_.*\\.csv$")
  
  # Find slider files that match the pattern
  slider_matched_files <- files[str_detect(basename(files), slider_pattern)]
  
  # Find data CSV files that match the pattern
  additional_csv_matched_files <- files[str_detect(basename(files), 
                                                   additional_csv_pattern)]
   
  # Create a directory for the current participant on the organized data path
  participant_folder <- file.path(organized_data_path, part_id)
  if(!dir.exists(participant_folder)) {
    dir.create(participant_folder, recursive = TRUE, showWarnings = TRUE)
  }
  
  # Create a subdirectory for slider files within the participant folder
  slider_folder <- file.path(participant_folder, paste0("slider_", part_id))
  if(!dir.exists(slider_folder)) {
    dir.create(slider_folder, recursive = TRUE, showWarnings = TRUE)
  }
  
  # Move slider matched files to the slider subfolder
  if(length(slider_matched_files) > 0) {
    for(file in slider_matched_files) {
      file_copy(file, file.path(slider_folder, basename(file)), overwrite = TRUE)
    }
  }
  
  # Move additional CSV matched files (experiment data) to the main participant folder 
  #and rename the participant folders
  if(length(additional_csv_matched_files) > 0) {
  # loop to rename the file during the copy process
  for(file in additional_csv_matched_files) {
    # New filename with '_raw_data'
    new_name <- paste0(part_id, "_raw_data.csv")
    # Copy and rename the file to the new name in the participant folder
    file_copy(file, file.path(participant_folder, new_name), overwrite = TRUE)
  }
}
  # check
  if(length(slider_matched_files) > 0 || length(additional_csv_matched_files) > 0) {
    cat("Files for participant ID '", part_id, 
        "' have been organized successfully. Slider files in: ", slider_folder, 
        ", other CSVs in: ", participant_folder, "\n")
  } else {
    cat("No files found for participant ID '", part_id, "'.\n")
  }
}

# # Put excel files (of digit in noise and digit span) in the organized data folder 
# 
# source_folder<-"/Users/irmakergin/Desktop/2023_speech_rate/data_experiment"
# destination_folder<-"//Users/irmakergin/Desktop/2023_speech_rate/organized_data_experiment"
# 
# # List all Excel files in the source folder
# excel_files <- dir_ls(path = source_folder, glob = "*.xlsx")
# 
# # Copy each Excel file to the destination folder- commented out to re-run
# for (file_path in excel_files) {
# dest_file_path <- file.path(destination_folder)
# file_copy(file_path, dest_file_path)
# # Check
# cat("Copied:", file_path, "to", dest_file_path, "\n")
# }

# Loop through each participant ID
for (part_id in participant_ids) {
  # Define the path to the participant's raw data CSV
  raw_data_path <- file.path(organized_data_path, 
                             part_id, 
                             paste0(part_id, "_raw_data.csv"))
# Read the CSV for each participant (if it exists)
if (file.exists(raw_data_path)) {
  df.raw <- read_csv(raw_data_path) %>%
    filter(!wav_file %in% c("Someday_trial_condition.wav", 
                            "Someday_trial_condition-5x.wav")) %>%
    mutate(index = row_number()) %>%
    select(index, participant, wav_file, old_name, segment_text, question, 
           C1, C2, C3, C4, C_correct, duration,
           A.numClicks, B.numClicks, C.numClicks, D.numClicks, slider.response, 
           summary, `textbox.text`) %>%
    group_by(wav_file) %>%
    summarise(
      index = first(index), 
      participant = first(participant), 
      old_name = first(old_name),
      segment_text = first(segment_text),
      question = first(question),
      C1 = first(C1),
      C2 = first(C2),
      C3 = first(C3),
      C4 = first(C4),
      C_correct = first(C_correct),
      duration = first(duration),
      summary = first(summary),
      textbox.text = first(textbox.text),
      A.numClicks = max(A.numClicks, na.rm = TRUE),
      B.numClicks = max(B.numClicks, na.rm = TRUE),
      C.numClicks = max(C.numClicks, na.rm = TRUE),
      D.numClicks = max(D.numClicks, na.rm = TRUE),
      likert_response = max(slider.response, na.rm = TRUE),
      .groups = 'drop'
    ) %>%
    arrange(index) %>%
    mutate(index = row_number()) 
  
  # Fill NA values in participant_id column with part_id for participant p_3
    if (part_id == "p_3") {
      df.raw <- df.raw %>%
        mutate(participant = replace_na(participant, part_id))
    }
    if (part_id == "p_1") {
      df.raw <- df.raw %>%
        mutate(participant = replace_na(participant, part_id))
    }
    if (part_id == "p_2") {
      df.raw <- df.raw %>%
        mutate(participant = replace_na(participant, part_id))
    }
   # Remove the extra last row from df.raw
    df.raw <- head(df.raw, n = -1)
   
  #Assign processed data of each participant to a new df
  assign(paste0("df.raw.merged_", part_id), df.raw, envir = .GlobalEnv)
  }
}
# Sanity check
# how many rows do we have- should be 125
nrow(df.raw.merged_p_2)
```

```{r}
# Merge all participant dfs into one df

# Create an empty data frame to store merged data
df.raw <- data.frame()

# Loop through each participant ID and merge their df
for (part_id in participant_ids) {
  # Construct the name of the data frame variable
  df_name <- paste0("df.raw.merged_", part_id)
  
  # Check if the data frame exists in the global environment
  if (exists(df_name, envir = .GlobalEnv)) {
    # Get the data frame from its name
    df_participant <- get(df_name, envir = .GlobalEnv)
    
    # Merge the data frame with the main merged data frame
    df.raw <- rbind(df.raw, df_participant)
  }
}
```

```{r}
# Add accuracy columns for multiple choice questions

# Calculate the multiple choice accuracy

df.raw<- df.raw %>%
  mutate(
    multiple_choice_accuracy = apply(., 1, function(row) {
      # Extract the first character from C_correct - it is the correct letter to click on
      correct_answer <- substr(row[["C_correct"]], 1, 1)
      
      # Determine which of the click columns matches the correct answer
      clicked_column <- ifelse(row[["A.numClicks"]] == 1, "A",
                               ifelse(row[["B.numClicks"]] == 1, "B",
                                      ifelse(row[["C.numClicks"]] == 1, "C",
                                             ifelse(row[["D.numClicks"]] == 1, "D", NA))))
      
      # Return 1 if the clicked column matches the correct answer, 0 otherwise
      if (!is.na(clicked_column) && clicked_column == correct_answer) {
        return(1)
      } else {
        return(0)
      }
    })
  )

# Change the column the order
df.raw<- df.raw[c("index", "participant", "wav_file", "old_name", 
                                 "duration","segment_text", 
                                 "question", "C1", "C2", "C3", "C4", "C_correct", 
                                 "A.numClicks", "B.numClicks", "C.numClicks",
                                 "D.numClicks", "multiple_choice_accuracy", 
                                 "likert_response", "summary","textbox.text")]
```

```{r}
# Extract the speech rate information from the trial name and create a speech_rate column
df.raw<- df.raw %>%
  mutate(speech_rate = case_when(
    str_detect(wav_file, "2x") ~ 2,
    str_detect(wav_file, "3x") ~ 3,
    str_detect(wav_file, "4x") ~ 4,
    str_detect(wav_file, "5x") ~ 5,
    TRUE ~ 1  # not sped up if there are no numbers + x in the name 
  ))
```


```{r}
# Add the Digit Span (working memory) scores of each participant

# Create an empty digit_span_score column
df.raw$digit_span_score <- NA

for (part_id in unique(df.raw$participant)) {
  # Construct the filename based on the participant ID
  filename <- paste0(organized_data_path, "/digit_span_", part_id, ".xlsx")
  
  # Check if the file exists
  if (file.exists(filename)) {
    # Correctly read the file using read_excel
    digit_span_data <- read_excel(filename)
    
    # Assuming the score is located in the first row of the 'score' column
    score <- digit_span_data$score[1]
      
    # Now this should work since digit_span_score column exists
    df.raw<- df.raw%>%
      mutate(digit_span_score = ifelse(participant == part_id, score, digit_span_score))
  } else {
    cat("File not found for participant", part_id, "\n")
  }
}
```

```{r}
# Add the hearWHO (digit-in-noise task for hearing in noise) scores of each participants

hearwho_pilot_data <- read_excel(paste0(organized_data_path,
                                        "/hearwho_experiment.xlsx"))

# Excel file has columns named 'participant' and 'score'
# Merge the scores into df.raw based on participant ID
df.raw <- merge(df.raw, hearwho_pilot_data[, c("participant", "score")], 
                       by.x = "participant", by.y = "participant", all.x = TRUE)

# Rename the 'score' column to 'digit_in_noise_score'
names(df.raw)[names(df.raw) == "score"] <- "digit_in_noise_score"
```


```{r}
# check
head(df.raw)
```

```{r}
# Add slider values and time points

# Check if the 'slider_values' column exists, if not, create it
if (!"slider_values" %in% names(df.raw)) {
  df.raw$slider_values <- NA
}

# Check if the 'slider_time' column exists, if not, create it
if (!"slider_time" %in% names(df.raw)) {
  df.raw$slider_time <- NA
}

# Define a function to extract and return slider values and time as strings
get_slider_values_and_time <- function(wav_file_name, part_id) {
  # Extract the trial number from wav_file name
  matches <- regmatches(wav_file_name, regexec("Someday_([0-9]+)", wav_file_name))
  if (length(matches[[1]]) < 2) { # If no match or match does not have a capture group
    return(list(values = NA, time = NA))
  }
  trial_number <- matches[[1]][2]

  # Construct the path to the slider file
  slider_file_path <- sprintf("%s/%s/slider_%s/*_%s_*.csv", 
                              organized_data_path, 
                              part_id, part_id, 
                              trial_number)

  # Find slider files matching the pattern
  slider_files <- Sys.glob(slider_file_path)
  
  if (length(slider_files) == 0) {
    return(list(values = NA, time = NA)) # No matching file found
  }
  
  slider_data <- read.csv(slider_files[1], skip = 1)

  # Prepare output for values
  slider_values_str <- if ("value" %in% colnames(slider_data)) {
    paste(slider_data$value, collapse = ",")
  } else {
    NA
  }

  # Prepare output for time, rounding to two decimals
  slider_time_str <- if ("time" %in% colnames(slider_data)) {
    rounded_times <- round(slider_data$time, 2)  # Round the time values to two decimal places
    paste(rounded_times, collapse = ",")
  } else {
    NA
  }

  return(list(values = slider_values_str, time = slider_time_str))
}

# Apply the function to each row of df.raw and extract results into separate columns
slider_info <- mapply(get_slider_values_and_time, 
                      df.raw$wav_file, 
                      df.raw$participant, 
                      SIMPLIFY = FALSE)  # Ensure output is a list to handle multiple return values

# Assign values and time from the list output to respective columns
df.raw$slider_values <- sapply(slider_info, '[[', "values")
df.raw$slider_time <- sapply(slider_info, '[[', "time")


```


```{r}
# correction for when participant number = trial number 

# Function to process slider file
process_slider_file <- function(participant_name, wav_file_name, file_path_name) {
  # Read the specified file
  slider_data <- read.csv(file_path_name, skip = 1)
  
  # Concatenate slider values into a string and round time values to two decimals
  if ("value" %in% colnames(slider_data) && "time" %in% colnames(slider_data)) {
    slider_values_str <- paste(slider_data$value, collapse = ",")
    slider_time_str <- paste(round(slider_data$time, 2), collapse = ",")
    
    # Count the number of slider values
    slider_values_count <- length(slider_data$value)
    cat("Number of slider values for", participant_name, ":", slider_values_count, "\n")
    
    # Count the number of time values
    slider_time_count <- length(slider_data$time)
    cat("Number of slider times for", participant_name, ":", slider_values_count, "\n")
    
    # Update df.raw with new slider values and time
    df.raw <- df.raw %>%
      mutate(
        slider_values = ifelse(participant == participant_name & wav_file == wav_file_name, 
                               slider_values_str, slider_values),
        slider_time = ifelse(participant == participant_name & wav_file == wav_file_name, 
                             slider_time_str, slider_time)
      )
  } else {
    cat("Missing 'value' or 'time' column in", file_path_name, "\n")
  }
  
  return(df.raw)
}

# List of participants and corresponding files
participants_files <- list(
  list("p_1", "Someday_1_condition-4x.wav", paste0(organized_data_path, "/", "p_1/slider_p_1/slider_p_1_001_Someday_1_condition-4x.wav.csv")),
  list("p_2", "Someday_2_condition-4x.wav", paste0(organized_data_path, "/", "p_2/slider_p_2/slider_p_2_001_Someday_2_condition-4x.wav.csv")),
  list("p_3", "Someday_3_condition-5x.wav", paste0(organized_data_path, "/", "p_3/slider_p_3/slider_p_3_001_Someday_3_condition-5x.wav.csv")),
  list("p_4", "Someday_4_condition-2x.wav", paste0(organized_data_path, "/", "p_4/slider_p_4/slider_p_4_001_Someday_4_condition-2x.wav.csv")),
  list("p_5", "Someday_5_condition-3x.wav", paste0(organized_data_path, "/", "p_5/slider_p_5/slider_p_5_001_Someday_5_condition-3x.wav.csv")),
   list("p_6", "Someday_6_condition-5x.wav", paste0(organized_data_path, "/",  "p_6/slider_p_6/slider_p_6_001_Someday_6_condition-5x.wav.csv")),
   list("p_7", "Someday_7_condition-5x.wav", paste0(organized_data_path, "/",  "p_7/slider_p_7/slider_p_7_001_Someday_7_condition-5x.wav.csv")),
  list("p_8", "Someday_8_condition-5x.wav", paste0(organized_data_path, "/",  "p_8/slider_p_8/slider_p_8_001_Someday_8_condition-5x.wav.csv")),
  list("p_9", "Someday_9_condition-3x.wav", paste0(organized_data_path, "/",  "p_9/slider_p_9/slider_p_9_001_Someday_9_condition-3x.wav.csv"))
  #list("p_10", "Someday_10_condition.wav", paste0(organized_data_path, "/",  #"p_10/slider_p_10/slider_p_10_001_Someday_10_condition.wav.csv")),
 # list("p_11", "Someday_11_condition-2x.wav", paste0(organized_data_path, "/",  #"p_11/slider_p_11/slider_p_11_001_Someday_11_condition-2x.wav.csv")),
  #list("p_12", "Someday_12_condition.wav", paste0(organized_data_path, "/",  #"p_12/slider_p_12/slider_p_12_001_Someday_12_condition.wav.csv"))
)


# Apply the function to each participant
for (p in participants_files) {
  df.raw <- process_slider_file(p[[1]], p[[2]], p[[3]])
}

```

```{r}
# Re-scale slider values to be between 0-1

# Convert slider_values from string to numeric lists 
df.raw$slider_values <- strsplit(as.character(df.raw$slider_values), 
                                        ",\\s*")
df.raw$slider_values <- lapply(df.raw$slider_values, 
                                      function(x) as.numeric(x))

rescale_values <- function(values) {
  sapply(values, function(x) x / 255)
}

# Apply the rescaling function to each row's slider_values
df.raw$slider_values_rescaled <- lapply(df.raw$slider_values, 
                                               rescale_values)
```

```{r}
# Sanity check: create a column showing number of slider values
df.raw <- df.raw %>%
  mutate(slider_values_number = lengths(slider_values_rescaled))
```

```{r}
# Depict slider movements

df.raw$slider_values_rescaled <- sapply(df.raw$slider_values_rescaled,
                                               function(x) paste(x, collapse = ","))

df.slider <- df.raw%>%
  mutate(slider_values_rescaled = strsplit(slider_values_rescaled, ",")) %>%
  mutate(slider_rescale_float = map(slider_values_rescaled, ~as.numeric(.x)))

df_long <- df.slider %>%
  mutate(id = row_number()) %>%
  unnest(slider_rescale_float) %>%
  rename(slider_value = slider_rescale_float) %>%
  group_by(id, speech_rate) %>%
  mutate(index = row_number()) %>%
  ungroup() %>%
  select(-slider_values_rescaled)

# Set the x-axis limits
p_slider_per_rate <- ggplot(df_long, aes(x = index,
                                         y = slider_value,
                                         group = interaction(id),
                                         color = as.factor(id))) +
  geom_line(alpha = 0.5, size = 0.5) +
  scale_x_continuous(name = "Index of the Slider Value") +
  scale_y_continuous(name = "Slider Value") +
  facet_wrap(~ speech_rate,
             scales = 'free_x',
             ncol = 1) +
  scale_color_manual(values = colorRampPalette(brewer.pal(12, "Paired"))
                     (length(unique(df_long$id)))) +
  theme(legend.position = "none") +
  labs(title = 'Slider Values by Speech Rate',
      caption = "Each line represents the comprehension trajectory at different speech rates.
      As the speech rate increases, comprehension scores seem to get lower."
)

# histograms

p_flipped_histogram_per_rate <- ggplot(df_long, aes(x = slider_value)) +
  geom_histogram(bins = 10, fill = "skyblue", color = "navy") +
  coord_flip() +
  facet_wrap(~speech_rate, scales = 'free_x', ncol = 1) +
  labs(y = "Slider Value Range", x = "Count", title = "Number of Slider Values by Speech Rate") +
  theme(legend.position = "none") +
  scale_y_continuous(labels = comma)

# combine
combined_plot <- p_slider_per_rate + p_flipped_histogram_per_rate +
  plot_layout(ncol = 2, widths = c(2, 1)) +
  theme(strip.background = element_rect(fill = "white", color = "black"))



print(combined_plot)

```

```{r}
# Sanity check for slider values 

rows_not_fitting_criteria_selected_columns <- df.raw %>%
  filter(
    (speech_rate == 1 & (slider_values_number < 6000 | slider_values_number > 8000)) |
    (speech_rate == 2 & (slider_values_number < 3000 | slider_values_number > 4000)) |
    (speech_rate == 3 & (slider_values_number < 2500 | slider_values_number > 3000)) |
    (speech_rate == 4 & (slider_values_number < 1500 | slider_values_number > 2000)) |
    (speech_rate == 5 & (slider_values_number < 1200 | slider_values_number > 1550)) 
  ) %>%
  select(participant, wav_file, index, slider_values_number)

# To print the resulting selected columns for rows that do not fit the criteria
print(rows_not_fitting_criteria_selected_columns)

# manually inspect those to see if they are just sampled slightly longer/ shorter or if the match is wrong
```


```{r}
# Only trials with the slider starting from point, with time one the x axis

# Modify df.slider to calculate a new column based on the condition
df.slider <- df.raw %>%
  mutate(
    slider_values_rescaled = strsplit(as.character(slider_values_rescaled), ","),
    slider_time_rescaled = strsplit(as.character(slider_time), ",")) %>%
  mutate(
    slider_rescale_float = map(slider_values_rescaled, ~as.numeric(.x)),
    slider_time_float = map(slider_time_rescaled, ~as.numeric(.x) / 1000)  # Convert from ms to seconds
  ) %>%
  rowwise() %>%
  mutate(include = ifelse(slider_values_rescaled[[1]][1] == 0, TRUE, FALSE)) %>%
  ungroup()

# Create a long format data frame with both time and values
df_long <- df.slider %>%
  filter(include) %>%
  mutate(id = row_number()) %>%
  unnest(c(slider_rescale_float, slider_time_float)) %>%
  rename(slider_value = slider_rescale_float, slider_times = slider_time_float) %>%
  group_by(id, speech_rate) %>%
  mutate(index = row_number()) %>%
  ungroup() %>%
  select(-slider_values_rescaled, -slider_time_rescaled, -include)  # Remove unnecessary columns for plotting

# Set the x-axis limits and labels
p_slider_per_rate <- ggplot(df_long, aes(x = slider_times,
                                         y = slider_value,
                                         group = interaction(id),
                                         color = as.factor(id))) +
  geom_line(alpha = 0.5, size = 0.5) +
  scale_x_continuous(name = "Time (seconds)") +
  scale_y_continuous(name = "Slider Value") +
  facet_wrap(~ speech_rate,
             scales = 'free_x',
             ncol = 1) +
  scale_color_manual(values = colorRampPalette(brewer.pal(12, "Paired"))
                     (length(unique(df_long$id)))) +
  theme(legend.position = "none") +
  labs(title = 'Slider Values by Speech Rate',
       caption = "Each line represents the comprehension trajectory at different speech rates.
       As the speech rate increases, comprehension scores seem to get lower.")

# Histograms
p_flipped_histogram_per_rate <- ggplot(df_long, aes(x = slider_value)) +
  geom_histogram(bins = 10, fill = "skyblue", color = "navy") +
  coord_flip() +
  facet_wrap(~speech_rate, scales = 'free_x', ncol = 1) +
  labs(y = "Slider Value Range", x = "Count", title = "Number of Slider Values by Speech Rate") +
  theme(legend.position = "none") +
  scale_y_continuous(labels = scales::comma)

# combine
combined_plot <- p_slider_per_rate + p_flipped_histogram_per_rate +
  plot_layout(ncol = 2, widths = c(2, 1)) +
  theme(strip.background = element_rect(fill = "white", color = "black"))
print(combined_plot)


```

## Calculations for the data exclusion criteria

For the post-hoc comprehension measures, to ensure that we are validating the novel measure against actual comprehension, following exclusion criteria will be applied: 

1. Absolute threshold for comprehension: 75% correctness on the multiple choice questions for the slowest (easiest to comprehend) speech rate.
```{r}
# Find trials that do not have a number right before .wav in the wav_file column 
# (slowest condition)
attention_check_trials <- df.raw %>%
  filter(!grepl("x\\.wav$", wav_file))

# Calculate the accuracy
accuracy_results <- attention_check_trials %>%
  group_by(participant) %>%
  summarise(
    accuracy = mean(multiple_choice_accuracy == 1, na.rm = TRUE),
    n = n()
  ) %>%
  mutate(passed = if_else(accuracy >= 0.75, TRUE, FALSE))

# Print out participants who passed or failed
passed_participants <- accuracy_results %>%
  filter(passed) %>%
  pull(participant)

failed_participants <- accuracy_results %>%
  filter(!passed) %>%
  pull(participant)

if(length(passed_participants) > 0) {
  cat(paste(passed_participants, collapse = ", "), 
      "passed the question accuracy criterion\n")
}

if(length(failed_participants) > 0) {
  cat(paste(failed_participants, collapse = ", "), 
      "failed the question accuracy criterion\n")
}
```

2. Ratings on the 10-point (post-hoc likert) scale should be significantly different for the slowest and fastest speech rates.

```{r}
# t-test 
participants <- unique(df.raw$participant)

# Create a vector to store results
rating_criteria_results <- character(length(participants))

# Loop through each participant
for (i in seq_along(participants)) {
  part_id <- participants[i]
  
  # Subset data for the current participant for slowest and fastest speech rates
  subset_data <- df.raw %>%
    filter(participant == part_id & (speech_rate == 1 | speech_rate == 4)) %>%
    select(likert_response, speech_rate)
  
  # Perform a t-test comparing likert_response for speech_rate 1 vs 4
  test_result <- t.test(likert_response ~ speech_rate, data = subset_data)
  
  # Check if the difference is significant (p-value < 0.05)
  if (test_result$p.value < 0.05) {
    rating_criteria_results[i] <- paste(part_id, "passed the rating criterion")
  } else {
    rating_criteria_results[i] <- paste(part_id, "failed the rating criterion")
  }
}

# Print the results
cat(rating_criteria_results, sep = "\n")
```

3. Participants shouldn't skip all the summaries
```{r}
# If all rows under textbox.tex are empty

# Check if all 'textbox.text' entries are empty for each participant
summary_criterion <- df.raw %>%
  group_by(participant) %>%
  summarize(all_empty = all(textbox.text == "" | is.na(textbox.text))) %>%
  ungroup()

# Print the results for participants where all textbox.text are empty
summary_criterion %>%
  filter(all_empty) %>%
  pull(participant) %>%
  walk(~ cat(.x, "failed summary criterion\n"))

# Print the results for participants where not all textbox.text are empty
summary_criterion %>%
  filter(!all_empty) %>%
  pull(participant) %>%
  walk(~ cat(.x, " passed summary criterion\n"))
```
For the physical slider to ensure that participants actually used it actively: Distribution of the amount of slider movements across trials and participants- If a participant's slider movements exceeds ±3.5 standard deviations from the mean, we will remove those participants' data.

```{r}
# Calculate movement score with magnitude for each trial
df.raw <- df.raw %>%
  rowwise() %>%
  mutate(trial_movement_score_magnitude = 
           ifelse(slider_values[[1]][1] == 0, sum(abs(diff(unlist(slider_values)))), NA))

# Aggregate these scores for each participant
participant_movement_scores <- df.raw %>%
  group_by(participant) %>%
  summarise(movement_score_all = sum(trial_movement_score_magnitude, na.rm = TRUE))

# Add the movement scores back to the df
df.raw <- left_join(df.raw, participant_movement_scores, by = "participant")

# Calculate mean and standard deviation for movement scores, identify outliers
mean_movement_score <- mean(participant_movement_scores$movement_score_all, na.rm = TRUE)
sd_movement_score <- sd(participant_movement_scores$movement_score_all, na.rm = TRUE)

cutoff_upper <- mean_movement_score + 3.5 * sd_movement_score
cutoff_lower <- mean_movement_score - 3.5 * sd_movement_score

outliers <- participant_movement_scores %>%
  filter(movement_score_all < cutoff_lower | movement_score_all > cutoff_upper) %>%
  pull(participant)

# Print participant IDs for those outside the ±3.5 SD range
cat("Participants outside the ±3.5 SD range:", paste(outliers, collapse = ", "), "\n")
```

Remove the participants that failed the criteria. 
-Participant 2 and 6 failed attention check 1. 

```{r}
# Remove 'p_2' and 'p_6" from dataset
df.raw <- df.raw %>%
  filter(participant != "p_2")
df.raw <- df.raw %>%
  filter(participant != "p_6")

# check
count(df.raw, participant)
```

## Save the organized data 
```{r}
# Convert list to string for slider values
df.raw$slider_values <- sapply(df.raw$slider_values, 
                                      function(x) paste(x, collapse = ","))

output_file_path <- file.path(organized_data_path, "organized_data_9p.csv")
write.csv(df.raw, output_file_path, row.names = FALSE)
```


## Visualize the slider movements after the elimination:

```{r}

# remove p_2 and p_6 from df slider (df_slider has been created before to depict slider movements)
df.slider <- df.slider %>%
  filter(participant != "p_2")
df.slider <- df.slider %>%
  filter(participant != "p_6")

df_long <- df.slider %>%
  mutate(id = row_number()) %>%
  unnest(slider_rescale_float) %>%
  rename(slider_value = slider_rescale_float) %>%
  group_by(id, speech_rate) %>%
  mutate(index = row_number()) %>%
  ungroup() %>%
  select(-slider_values_rescaled)

# Set the x-axis limits
p_slider_per_rate <- ggplot(df_long, aes(x = index,
                                         y = slider_value,
                                         group = interaction(id),
                                         color = as.factor(id))) +
  geom_line(alpha = 0.5, size = 0.5) +
  scale_x_continuous(name = "Index of the Slider Value") +
  scale_y_continuous(name = "Slider Value") +
  facet_wrap(~ speech_rate,
             scales = 'free_x',
             ncol = 1) +
  scale_color_manual(values = colorRampPalette(brewer.pal(12, "Paired"))
                     (length(unique(df_long$id)))) +
  theme(legend.position = "none") +
  labs(title = 'Slider Values by Speech Rate',
      caption = "Each line represents the comprehension trajectory at different speech rates.
      As the speech rate increases, comprehension scores seem to get lower."
)

# histograms

p_flipped_histogram_per_rate <- ggplot(df_long, aes(x = slider_value)) +
  geom_histogram(bins = 10, fill = "skyblue", color = "navy") +
  coord_flip() +
  facet_wrap(~speech_rate, scales = 'free_x', ncol = 1) +
  labs(y = "Slider Value Range", x = "Count", title = "Number of Slider Values by Speech Rate") +
  theme(legend.position = "none") +
  scale_y_continuous(labels = comma)

# combine
combined_plot <- p_slider_per_rate + p_flipped_histogram_per_rate +
  plot_layout(ncol = 2, widths = c(2, 1)) +
  theme(strip.background = element_rect(fill = "white", color = "black"))

print(combined_plot)
```


```{r}
# upload data after semantic similarity calculations
df.data <- read.csv(file.path(organized_data_path, "df_semantic.csv"))
```


```{r}
# Only trials with the slider starting from point, with time one the x axis

# Modify df.slider to calculate a new column based on the condition
df.slider <- df.data %>%
  mutate(
    slider_values_rescaled = strsplit(as.character(slider_values_rescaled), ","),
    slider_time_rescaled = strsplit(as.character(slider_time), ",")) %>%
  mutate(
    slider_rescale_float = map(slider_values_rescaled, ~as.numeric(.x)),
    slider_time_float = map(slider_time_rescaled, ~as.numeric(.x) / 1000)  # Convert from ms to seconds
  ) %>%
  rowwise() %>%
  mutate(include = ifelse(slider_values_rescaled[[1]][1] == 0, TRUE, FALSE)) %>%
  ungroup()

# Create a long format data frame with both time and values
df_long <- df.slider %>%
  filter(include) %>%
  mutate(id = row_number()) %>%
  unnest(c(slider_rescale_float, slider_time_float)) %>%
  rename(slider_value = slider_rescale_float, slider_times = slider_time_float) %>%
  group_by(id, speech_rate) %>%
  mutate(index = row_number()) %>%
  ungroup() %>%
  select(-slider_values_rescaled, -slider_time_rescaled, -include)  # Remove unnecessary columns for plotting

# Set the x-axis limits and labels
p_slider_per_rate <- ggplot(df_long, aes(x = slider_times,
                                         y = slider_value,
                                         group = interaction(id),
                                         color = as.factor(id))) +
  geom_line(alpha = 0.5, size = 0.5) +
  scale_x_continuous(name = "Time (seconds)") +
  scale_y_continuous(name = "Slider Value") +
  facet_wrap(~ speech_rate,
             scales = 'free_x',
             ncol = 1) +
  scale_color_manual(values = colorRampPalette(brewer.pal(12, "Paired"))
                     (length(unique(df_long$id)))) +
  theme(legend.position = "none") +
  labs(title = 'Slider Values by Speech Rate',
       caption = "Each line represents the slider trajectory.
       As the speech rate increases, comprehension scores seem to get lower.")

# Histograms
p_flipped_histogram_per_rate <- ggplot(df_long, aes(x = slider_value)) +
  geom_histogram(bins = 10, fill = "skyblue", color = "navy") +
  coord_flip() +
  facet_wrap(~speech_rate, scales = 'free_x', ncol = 1) +
  labs(y = "Slider Value Range", x = "Count", title = "Number of Slider Values by Speech Rate") +
  theme(legend.position = "none") +
  scale_y_continuous(labels = scales::comma)

# combine
combined_plot <- p_slider_per_rate + p_flipped_histogram_per_rate +
  plot_layout(ncol = 2, widths = c(2, 1)) +
  theme(strip.background = element_rect(fill = "white", color = "black"))
print(combined_plot)


```

```{r}
# Compute mean & median slider values for each trial with rescaled values  
df.data <- df.data %>%
  mutate(
    slider_values_numeric = str_split(slider_values_rescaled, ",") %>%
      map(~ as.numeric(.x))
  )


# Mean and median slider values for each trial
df.data <- df.data %>%
  rowwise() %>%
  mutate(trial_mean_rescaled = mean(unlist(slider_values_numeric), na.rm = TRUE),
         trial_median_rescaled = median(unlist(slider_values_numeric), na.rm = TRUE)) %>%
  ungroup()

```

```{r}
# CHECK IF MEAN AND MEDIAN CALCULATIONS ARE CORRECT
```

# Analysis

## Individual fixed effects

We conducted Mixed Effects Linear Regression Analyses to model the median real-time comprehension scores. Firstly, we wanted to how each post-hoc tests, which are the multiple-choice questions, 10-scale comprehension ratings, and summaries, can predict the real-time comprehension scores alone. Digit Span and Digit-In-Noise scores are assigned as random effects, accounting for individual subject variations.

### Post-hoc Comprehension Ratings
```{r}
# post-hoc comprehension ratings
model_likert<- lmer(trial_median_rescaled ~ 
                likert_response + 
                (1 | digit_span_score) + 
                (1 | digit_in_noise_score), data = df.data)

summary(model_likert)
```
For the random effects, the variance and standard deviation for the digit span score were 0.00 and 0.03, respectively. The hearing-in-noise score did not contribute significantly to the variance (variance = 0.00, SD = 0.00). The residual variance was 0.03 (SD = 0.19). The post-hoc comrehension rating significantly predicted the trial median real-time comrehension ratings (B = 0.10, SE = 0.002, t = 56.85, p < .001).


### Multiple Choice Quesitons
```{r}
# multiple choice questions
model_multiple_choice<- lmer(trial_median_rescaled ~ 
                multiple_choice_accuracy + 
                (1 | digit_span_score) + 
                (1 | digit_in_noise_score), data = df.data)

summary(model_multiple_choice)
```

The variance and standard deviation for the digit span score were 0.00 and 0.04, respectively. The hearing-in-noise score had a variance of 0.00 and a standard deviation of 0.07. The residual variance was 0.14 (SD = 0.37). Multiple choice question accuracy significantly predicted the real-time comprehension measure values (B = 0.34, SE = 0.03, t = 12.50, p < .001), indicating a strong positive relationship.

```{r}
# Calculate the average multiple_choice_accuracy scores per speech_rate category
average_scores <- df.data %>%
  group_by(speech_rate) %>%
  summarise(average_accuracy = mean(multiple_choice_accuracy, na.rm = TRUE),
    sd = sd(multiple_choice_accuracy, na.rm = TRUE),
    n = n(),
    se = sd / sqrt(n)  # standard error
  )

# plot
ggplot(average_scores, aes(x = factor(speech_rate), y = average_accuracy)) +
  geom_bar(stat = "identity", fill = "lightpink") +  
  labs(x = "Speech Rate", 
       y = "Average Multiple Choice Accuracy", 
       title = "Average Multiple Choice Accuracy by Speech Rate") +
  geom_text(aes(label = round(average_accuracy, 2)), vjust = -1.6, size = 3.5)+
  geom_errorbar(aes(ymin = average_accuracy - se, ymax = average_accuracy + se), 
                width = 0.25, position = position_dodge(width = 0.9)) 
```


### Summary

```{r}
# Summary- Glove (sum of maximum cosine values of summary words)
model_glove1<- lmer(trial_median_rescaled ~ 
                glove_sum_max_similarity + 
                (1 | digit_span_score) + 
                (1 | digit_in_noise_score), data = df.data)

summary(model_glove1)
```

For the random effects, the variance and standard deviation for the digit span score were 0.02 and 0.12, respectively. The hearing-in-noise score did not contribute significantly to the variance (variance = 0.00, SD = 0.00). The sum of maximum cosine values of summary words calculated using GLoVe significantly predicted the real-time comprehension measure values (B = 0.03, SE = 0.002, t = 19.86, p < .001).

```{r}
# Summary- Glove (average of maximum cosine values of segment text words)
model_glove2 <- lmer(trial_median_rescaled ~  
                glove_text_average_max_similarity +
                (1 | digit_span_score) + 
                (1 | digit_in_noise_score), data = df.data)

summary(model_glove2)
```
The working memory and hearing-in-noise scores accounted almost no variance in the model (variance= 0.00, SD = 0.03 and variance = 0.00, SD = 0.04, respectively).The average of maximum cosine values of segment words, calculated using GLoVe, predicted the trial median rescaled values (B = 1.85, SE = 0.15, t = 12.19, p < .001)

```{r}
# Summary- BERT (cosine values of summaries)
model_bert <- lmer(trial_median_rescaled ~  
                bert_cosine_similarity +
                (1 | digit_span_score) + 
                (1 | digit_in_noise_score), data = df.data)

summary(model_bert)
```
The working memory and hearing-in-noise scores accounted almost no variance in the model (variance= 0.00, SD = 0.03 and variance = 0.00, SD = 0.04, respectively).The BERT cosine similarity significantly predicted the real-time comprehension measure values (B = 1.20, SE = 0.10, t = 11.65, p < .001).

```{r figure-size, fig.width=15, fig.height=12}
# Visualize summary scores per speech rate

# glove- summaries
average_similarity <- df.data %>%
  group_by(speech_rate) %>%
  summarise(
    average_similarity = mean( glove_sum_max_similarity, na.rm = TRUE),
    sd = sd(glove_sum_max_similarity, na.rm = TRUE),
    n = n(),
    se = sd / sqrt(n)  # standard error
  )

print(average_similarity[, c("speech_rate", "sd", "n", "se")])

# Plot 
plot_glove_summary <-  ggplot(average_similarity, aes(x = factor(speech_rate), 
                               y = average_similarity, 
                               fill = as.factor(speech_rate))) +
  geom_bar(stat = "identity", position = "dodge", fill = "darkseagreen1") +
  labs(x = "Speech Rate", y = "Average Similarity", 
       title = "GloVe- Average of Sum of Maximum Cosine Values for Summary Words By Speech Rate") +
  geom_text(aes(label = round(average_similarity, 2)), 
            vjust = -1.1, position = position_dodge(width = 0.9), size = 3) +
  geom_errorbar(aes(ymin = average_similarity - se, ymax = average_similarity + se), 
                width = 0.25, position = position_dodge(width = 0.9)) + 
  theme(plot.title = element_text(size = 13,hjust = 0.5)  # arange title
)

# Glove- over text (not over summary)
average_similarity <- df.data %>%
  group_by(speech_rate) %>%
  summarise(
    average_similarity = mean( glove_text_average_max_similarity, na.rm = TRUE),
    sd = sd( glove_text_average_max_similarity, na.rm = TRUE),
    n = n(),
    se = sd / sqrt(n)  # standard error
  )

print(average_similarity[, c("speech_rate", "sd", "n", "se")])

# Plot 
plot_glove_text <- ggplot(average_similarity, aes(x = factor(speech_rate), 
                               y = average_similarity, 
                               fill = as.factor(speech_rate))) +
  geom_bar(stat = "identity", position = "dodge", fill = "darkseagreen2") +
  labs(x = "Speech Rate", y = "Average Similarity", 
       title = "GloVe- Average of Maximum Cosine Values For Segment Text Words By Speech Rate") +
  geom_text(aes(label = round(average_similarity, 2)), 
            vjust = -0.7, position = position_dodge(width = 0.9), size = 3) +
  geom_errorbar(aes(ymin = average_similarity - se, ymax = average_similarity + se), 
                width = 0.25, position = position_dodge(width = 0.9)) +
  theme(plot.title = element_text(size = 13,hjust = 0.5)  # margins
)

# BERT with whole summary-whole text

average_similarity <- df.data %>%
  group_by(speech_rate) %>%
  summarise(
    average_similarity = mean(bert_cosine_similarity, na.rm = TRUE),
    sd = sd(bert_cosine_similarity, na.rm = TRUE),
    n = n(),
    se = sd / sqrt(n)  # standard error
  )

print(average_similarity[, c("speech_rate", "sd", "n", "se")])

# Plot 
plot_bert <- ggplot(average_similarity, aes(x = factor(speech_rate), 
                               y = average_similarity, 
                               fill = as.factor(speech_rate))) +
  geom_bar(stat = "identity", position = "dodge", fill = "darkseagreen3") +
  labs(x = "Speech Rate", y = "Average Similarity", 
       title = "BERT Semantic Similarity by Speech Rate") +
  geom_text(aes(label = round(average_similarity, 2)), 
            vjust = -1, position = position_dodge(width = 0.9), size = 3) +
  geom_errorbar(aes(ymin = average_similarity - se, ymax = average_similarity + se), 
                width = 0.25, position = position_dodge(width = 0.9)) +
  theme(plot.title = element_text(size = 13,hjust = 0.5)  # margins
)
# Arrange plots in a single column grid
grid.arrange(plot_glove_summary, plot_glove_text, plot_bert, ncol = 1)

```

## All psot-hoc measures as fixed effects
A Mixed Effects Linear Regression Analysis is conducted to model the median real-time comprehension scores. Comprehension scores of the post-hoc tests, which are the multiple-choice questions, 10-scale comprehension ratings, and summaries, are utilized as factors in the regression. Digit Span and Digit-In-Noise scores are assigned as random effects, accounting for individual subject variations. This approach allows us to explore to what degree the scores of our novel real-time comprehension measure can be explained by comprehension, above and beyond the contribution of individual differences in working memory and speech perception in noise capacities.

We conducted the same regression analysis with different semantic similarity calculations to see whether calculating semantic similarities with different embedding models creates a diffece in how semantic similarity can predict the novel measure.

```{r}
model_all_glove1 <- lmer(trial_median_rescaled ~  
                glove_sum_max_similarity +
                likert_response + 
                multiple_choice_accuracy + 
                (1 | digit_span_score) + 
                (1 | digit_in_noise_score), data = df.data)

summary(model_all_glove1)
```

The working memory and hearing-in-noise scores accounted almost no variance in the model (variance= 0.001, SD = 0.03 and variance = 0.00, SD = 0.04, respectively).The post-hoc rating values significantly predicted real-time comprehension ratings (B = 0.10, SE = 0.004, t = 25.45, p < .001). Additionally, multiple choice accuracy was positively associated with real-time comprehension ratings (B = 0.05, SE = 0.02, t = 2.51, p = .01). However, the semantic similarity measure was not significantly associated with the real-time comprehension ratings (B = 0.00, SE = 0.02, t = 0.91, p = .36).

```{r}
# Depict the likert scale and slider values for each speech rate. Their patterns should look quite similar based on the regression analysis 

# Calculate the average  likert_response scores per speech_rate category
average_likert_scores <- df.data %>%
  group_by(speech_rate) %>%
  summarise(average_likert = mean(likert_response, na.rm = TRUE))

# Plotting the average likert scale across speech rates
p1 <- ggplot(average_likert_scores, aes(x = factor(speech_rate), y = average_likert)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  labs(x = "Speech Rate", y = "Post-hoc Rating Scores", title = "Average Post-hoc Ratings 
       per Speech Rate") +
  geom_text(aes(label = round(average_likert, 2)), vjust = -0.5, size = 3.5)

# Calculate the average trial_median_rescaled for each speech_rate category
average_trial_median <- df.data %>%
  group_by(speech_rate) %>%
  summarise(average_trial_median = mean(trial_median_rescaled, na.rm = TRUE))

# Plot
p2 <- ggplot(average_trial_median, aes(x = factor(speech_rate), y = average_trial_median, 
                                       fill = as.factor(speech_rate))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "Pastel1", name = "Speech Rate") +
  labs(x = "Speech Rate", y = "Real-Time Comprehension Scores", 
  title = "  Average of the Median 
Real-Time Comprehension Scores 
       per Speech Rate") +
  geom_text(aes(label = round(average_trial_median, 2)), vjust = -0.3, 
            position = position_dodge(width = 0.9), size = 3) +
  theme(legend.position = "none")

# Arrange the plots side by side
combined_plot <- p1 + p2 + plot_layout(ncol = 2)
print(combined_plot)
```

```{r}
model_all_glove2 <- lmer(trial_median_rescaled ~  
                glove_text_average_max_similarity +
                likert_response + 
                multiple_choice_accuracy + 
                (1 | digit_span_score) + 
                (1 | digit_in_noise_score), data = df.data)

summary(model_all_glove2)
```

For the random effects, the variance and standard deviation for the digit span score were 0.00 and 0.03, respectively. The hearing-in-noise score did not contribute significantly to the variance (variance = 0.00, SD = 0.00). The residual variance was 0.03 (SD = 0.19). The GloVe text average max similarity also did not significantly predict trial median rescaled values (B = -0.12, SE = 0.10, t = -1.15, p = .25). However, the Likert response significantly predicted trial median rescaled values (B = 0.10, SE = 0.003, t = 31.80, p < .001). Additionally, multiple choice accuracy significantly predicted trial median rescaled values (B = 0.05, SE = 0.02, t = 2.56, p = .01).

```{r}
model_all_bert <- lmer(trial_median_rescaled ~  
                bert_cosine_similarity +
                likert_response + 
                multiple_choice_accuracy + 
                (1 | digit_span_score) + 
                (1 | digit_in_noise_score), data = df.data)

summary(model_all_bert)
```

For the random effects, the variance and standard deviation for the digit span score were 0.00 and 0.03, respectively. The hearing-in-noise score did not contribute significantly to the variance (variance = 0.00, SD = 0.00). The residual variance was 0.03 (SD = 0.19).
Fixed effects analysis showed that the intercept significantly predicted trial median rescaled values (B = -0.13, SE = 0.03, t = -4.84, p < .001). The BERT cosine similarity did not significantly predict trial median rescaled values (B = -0.07, SE = 0.07, t = -1.03, p = .30). However, the Likert response significantly predicted trial median rescaled values (B = 0.10, SE = 0.003, t = 32.21, p < .001). Additionally, multiple choice accuracy significantly predicted trial median rescaled values (B = 0.05, SE = 0.02, t = 2.55, p = .01).

## Predicting speech rate from measures 
we investigated whether comprehension changes based on speech rate by conducting a Mixed Effects Linear Regression with all comprehension measures as fixed effects. 
```{r}
model_rate <- lmer(speech_rate ~ 
                trial_median_rescaled +
                glove_sum_max_similarity +
                likert_response + 
                multiple_choice_accuracy + 
                (1 | digit_span_score) + 
                (1 | digit_in_noise_score), data = df.data)

summary(model_rate)
```

For the random effects, the variance and standard deviation for the digit span score were 0.10 and 0.31, respectively. The hearing-in-noise score did not contribute significantly to the variance (variance = 0.00, SD = 0.00). The residual variance was 0.29 (SD = 0.54).
Real-time comprehension scores significantly predicted speech rate (B = -1.88, SE = 0.13, t = -13.96, p < .001). The GloVe sum max similarity also significantly predicted speech rate (B = -0.01, SE = 0.005, t = -2.56, p = .01). Likert response significantly predicted speech rate (B = -0.13, SE = 0.02, t = -7.39, p < .001). However, multiple choice accuracy did not significantly predict speech rate (B = -0.07, SE = 0.06, t = -1.24, p = .22).

```{r}
plot<- df.data %>%
  ggplot(aes(speech_rate, trial_median_rescaled)) + geom_point() + theme_bw() +
  geom_smooth(method="lm", alpha=0.5, color='violet', size=1)
plot
```

Model comparison (anova) btw semantic similarty models?