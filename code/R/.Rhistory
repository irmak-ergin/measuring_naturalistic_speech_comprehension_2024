C3 = first(C3),
C4 = first(C4),
C_correct = first(C_correct),
duration = first(duration),
`Experimen_audio.started` = first(`Experimen_audio.started`),
summary = first(summary),
textbox.text = first(textbox.text),
A.numClicks = max(A.numClicks, na.rm = TRUE),
B.numClicks = max(B.numClicks, na.rm = TRUE),
C.numClicks = max(C.numClicks, na.rm = TRUE),
D.numClicks = max(D.numClicks, na.rm = TRUE),
likert_response = max(slider.response, na.rm = TRUE),
summary_skipped = if_else(is.infinite(max(`skip_button_exp.numClicks`,
na.rm = TRUE)),
NA_real_, max(`skip_button_exp.numClicks`,
na.rm = TRUE)),
.groups = 'drop'
) %>%
arrange(index) %>%
mutate(index = row_number())
#  Assign processed data of each participant to a new df
assign(paste0("df.raw.merged_", part_id), df.raw, envir = .GlobalEnv)
}
}
# Sanity check
# how many rows do we have- should be 150
nrow(df.raw.merged_p_1)
# how many summary=yes do we have? - should be 48
summary_yes_count <- df.raw.merged_p_1 %>%
filter(summary == "yes") %>%
nrow()
print(summary_yes_count)
# Merge all participant dfs into one df
# Create an empty data frame to store merged data
df.raw.merged <- data.frame()
# Loop through each participant ID and merge their df
for (part_id in participant_ids) {
# Construct the name of the data frame variable
df_name <- paste0("df.raw.merged_", part_id)
# Check if the data frame exists in the global environment
if (exists(df_name, envir = .GlobalEnv)) {
# Get the data frame from its name
df_participant <- get(df_name, envir = .GlobalEnv)
# Merge the data frame with the main merged data frame
df.raw.merged <- rbind(df.raw.merged, df_participant)
}
}
# Calculate the multiple choice accuracy
df.raw.merged <- df.raw.merged %>%
mutate(
multiple_choice_accuracy = apply(., 1, function(row) {
# Extract the first character from C_correct - it is the correct letter to click on
correct_answer <- substr(row[["C_correct"]], 1, 1)
# Determine which of the click columns matches the correct answer
clicked_column <- ifelse(row[["A.numClicks"]] == 1, "A",
ifelse(row[["B.numClicks"]] == 1, "B",
ifelse(row[["C.numClicks"]] == 1, "C",
ifelse(row[["D.numClicks"]] == 1, "D", NA))))
# Return 1 if the clicked column matches the correct answer, 0 otherwise
if (!is.na(clicked_column) && clicked_column == correct_answer) {
return(1)
} else {
return(0)
}
})
)
# Change the column the order
df.raw.merged <- df.raw.merged[c("index", "participant", "wav_file", "old_name",
"duration", "Experimen_audio.started","segment_text",
"question", "C1", "C2", "C3", "C4", "C_correct",
"A.numClicks", "B.numClicks", "C.numClicks",
"D.numClicks", "multiple_choice_accuracy",
"likert_response", "summary", "summary_skipped",
"textbox.text")]
# Add the Digit Span (working memory) scores of each participant
# Create an empty digit_span_score column
df.raw.merged$digit_span_score <- NA
for (part_id in unique(df.raw.merged$participant)) {
# Construct the filename based on the participant ID
filename <- paste0(organized_data_path, "/digit_span_", part_id, ".xlsx")
# Check if the file exists
if (file.exists(filename)) {
# Correctly read the file using read_excel
digit_span_data <- read_excel(filename)
# Assuming the score is located in the first row of the 'score' column
score <- digit_span_data$score[1]
# Now this should work since digit_span_score column exists
df.raw.merged <- df.raw.merged %>%
mutate(digit_span_score = ifelse(participant == part_id, score, digit_span_score))
} else {
cat("File not found for participant", part_id, "\n")
}
}
# Add the hearWHO (digit-in-noise task for hearing in noise) scores of each participants
hearwho_pilot_data <- read_excel(paste0(organized_data_path, "/hearwho_pilot.xlsx"))
# Excel file has columns named 'participant' and 'score'
# Merge the scores into df.raw.merged based on participant ID
df.raw.merged <- merge(df.raw.merged, hearwho_pilot_data[, c("participant", "score")],
by.x = "participant", by.y = "participant", all.x = TRUE)
# Rename the 'score' column to 'digit_in_noise_score'
names(df.raw.merged)[names(df.raw.merged) == "score"] <- "digit_in_noise_score"
# Rescale post-hoc the likert scale values that are between 1-10 to 0-1
df.raw.merged$likert_response <- (df.raw.merged$likert_response - 1) / 9
# Find the slider values for each trial and save them to the df
participants <- unique(df.raw.merged$participant)
# Add a new column for slider values
if (!"slider_values" %in% names(df.raw.merged)) {
df.raw.merged$slider_values <- NA
}
# Define a function to extract and return slider values as a string
get_slider_values <- function(wav_file_name, part_id) {
# Extract the trial number from wav_file name
matches <- regmatches(wav_file_name, regexec("Someday_([0-9]+)", wav_file_name))
if (length(matches[[1]]) < 2) { # If no match or match does not have a capture group
return(NA)
}
trial_number <- matches[[1]][2]
# Construct the path to the slider file
slider_file_path <- sprintf("%s/%s/slider_%s/*_%s_*.csv",
organized_data_path,
part_id, part_id,
trial_number)
# Find slider files matching the pattern
slider_files <- Sys.glob(slider_file_path)
if (length(slider_files) == 0) {
return(NA) # No matching file found
}
slider_data <- read.csv(slider_files[1], skip = 1)
if ("value" %in% colnames(slider_data)) {
# Concatenate slider values into a string
return(paste(slider_data$value, collapse = ","))
} else {
return(NA)
}
}
# Apply the function to each row of df.raw.merged
df.raw.merged$slider_values <- mapply(get_slider_values,
df.raw.merged$wav_file,
df.raw.merged$participant)
# Correct for  the cases when participant id= trial id
participant_name <- "p_1"
wav_file_name <- "Someday_1_condition.wav"
file_path_name <- paste0(organized_data_path, "/",
"p_1/slider_p_1/slider_p_1_001_Someday_1_condition.wav.csv")
# Read the specified file
slider_data <- read.csv(file_path_name, skip = 1)
# Concatenate slider values into a string
slider_values_str <- paste(slider_data$value, collapse = ",")
# Count the number of slider values
slider_values_count <- length(slider_data$value)
cat("Number of slider values:", slider_values_count, "\n")
# Update the df.raw.merged dataframe with the new slider values
df.raw.merged <- df.raw.merged %>%
mutate(slider_values=ifelse(participant == participant_name & wav_file == wav_file_name,
slider_values_str, slider_values))
participant_name <- "p_2"
wav_file_name <- "Someday_2_condition.wav"
file_path_name <- paste0(organized_data_path, "/",
"p_2/slider_p_2/slider_p_2_001_Someday_2_condition.wav.csv")
# Read the specified file
slider_data <- read.csv(file_path_name, skip = 1)
# Concatenate slider values into a string
slider_values_str <- paste(slider_data$value, collapse = ",")
# Count the number of slider values
slider_values_count <- length(slider_data$value)
cat("Number of slider values:", slider_values_count, "\n")
# Update the df.raw.merged dataframe with the new slider values
df.raw.merged <- df.raw.merged %>%
mutate(slider_values=ifelse(participant == participant_name & wav_file == wav_file_name,
slider_values_str, slider_values))
participant_name <- "p_3"
wav_file_name <- "Someday_3_condition-3x.wav"
file_path_name <- paste0(organized_data_path, "/",
"p_3/slider_p_3/slider_p_3_001_Someday_3_condition-3x.wav.csv")
# Read the specified file
slider_data <- read.csv(file_path_name, skip = 1)
# Concatenate slider values into a string
slider_values_str <- paste(slider_data$value, collapse = ",")
# Count the number of slider values
slider_values_count <- length(slider_data$value)
cat("Number of slider values:", slider_values_count, "\n")
# Update the df.raw.merged dataframe with the new slider values
df.raw.merged <- df.raw.merged %>%
mutate(slider_values=ifelse(participant == participant_name & wav_file == wav_file_name,
slider_values_str, slider_values))
participant_name <- "p_4"
wav_file_name <- "Someday_4_condition-2x.wav"
file_path_name <- paste0(organized_data_path, "/",
"p_4/slider_p_4/slider_p_4_001_Someday_4_condition-2x.wav.csv" )
# Read the specified file
slider_data <- read.csv(file_path_name, skip = 1)
# Concatenate slider values into a string
slider_values_str <- paste(slider_data$value, collapse = ",")
# Count the number of slider values
slider_values_count <- length(slider_data$value)
cat("Number of slider values:", slider_values_count, "\n")
# Update the df.raw.merged dataframe with the new slider values
df.raw.merged <- df.raw.merged %>%
mutate(slider_values=ifelse(participant == participant_name & wav_file == wav_file_name,
slider_values_str, slider_values))
participant_name <- "p_5"
wav_file_name <- "Someday_5_condition-3-5x.wav"
file_path_name <- paste0(organized_data_path, "/",
"p_5/slider_p_5/slider_p_5_001_Someday_5_condition-3-5x.wav.csv")
# Read the specified file
slider_data <- read.csv(file_path_name, skip = 1)
# Concatenate slider values into a string
slider_values_str <- paste(slider_data$value, collapse = ",")
# Count the number of slider values
slider_values_count <- length(slider_data$value)
cat("Number of slider values:", slider_values_count, "\n")
# Update the df.raw.merged dataframe with the new slider values
df.raw.merged <- df.raw.merged %>%
mutate(slider_values=ifelse(participant == participant_name & wav_file == wav_file_name,
slider_values_str, slider_values))
# Rescale slider values to be between 0-1
# Convert slider_values from string to numeric lists
df.raw.merged$slider_values <- strsplit(as.character(df.raw.merged$slider_values),
",\\s*")
df.raw.merged$slider_values <- lapply(df.raw.merged$slider_values,
function(x) as.numeric(x))
rescale_values <- function(values) {
sapply(values, function(x) x / 255)
}
# Apply the rescaling function to each row's slider_values
df.raw.merged$slider_values_rescaled <- lapply(df.raw.merged$slider_values,
rescale_values)
# Compute mean & median slider values for each trial & across trials with rescaled values
# Mean and median slider values for each trial
df.raw.merged <- df.raw.merged %>%
rowwise() %>%
mutate(trial_mean_rescaled = mean(unlist(slider_values_rescaled), na.rm = TRUE),
trial_median_rescaled = median(unlist(slider_values_rescaled), na.rm = TRUE)) %>%
ungroup()
# Mean and median slider values across trials for each participant
participant_stats_rescaled <- df.raw.merged %>%
group_by(participant) %>%
summarise(participant_mean_rescaled = mean(trial_mean_rescaled, na.rm = TRUE),
participant_median_rescaled = median(trial_median_rescaled, na.rm = TRUE))
# Add the participant level stats back to the df
df.raw.merged <- left_join(df.raw.merged, participant_stats_rescaled, by = "participant")
# Extract the speech rate information from the trial name and create a speech_rate column
df.raw.merged <- df.raw.merged %>%
mutate(speech_rate = case_when(
str_detect(wav_file, "2x") ~ 2,
str_detect(wav_file, "2-5x") ~ 2.5,
str_detect(wav_file, "3x") ~ 3,
str_detect(wav_file, "3-5x") ~ 3.5,
str_detect(wav_file, "4x") ~ 4,
TRUE ~ 1  # not sped up if there are no numbers + x in the name
))
# Find trials that do not have a number right before .wav in the wav_file column
# (slowest condition)
attention_check_trials <- df.raw.merged %>%
filter(!grepl("x\\.wav$", wav_file))
# Calculate the accuracy
accuracy_results <- attention_check_trials %>%
group_by(participant) %>%
summarise(
accuracy = mean(multiple_choice_accuracy == 1, na.rm = TRUE),
n = n()
) %>%
mutate(passed = if_else(accuracy >= 0.75, TRUE, FALSE))
# Print out participants who passed or failed
passed_participants <- accuracy_results %>%
filter(passed) %>%
pull(participant)
failed_participants <- accuracy_results %>%
filter(!passed) %>%
pull(participant)
if(length(passed_participants) > 0) {
cat(paste(passed_participants, collapse = ", "),
"passed the question accuracy criterion\n")
}
if(length(failed_participants) > 0) {
cat(paste(failed_participants, collapse = ", "),
"failed the question accuracy criterion\n")
}
# t-test
# Create a vector to store results
rating_criteria_results <- character(length(participants))
# Loop through each participant
for (i in seq_along(participants)) {
part_id <- participants[i]
# Subset data for the current participant for slowest and fastest speech rates
subset_data <- df.raw.merged %>%
filter(participant == part_id & (speech_rate == 1 | speech_rate == 4)) %>%
select(likert_response, speech_rate)
# Perform a t-test comparing likert_response for speech_rate 1 vs 4
test_result <- t.test(likert_response ~ speech_rate, data = subset_data)
# Check if the difference is significant (p-value < 0.05)
if (test_result$p.value < 0.05) {
rating_criteria_results[i] <- paste(part_id, "passed the rating criterion")
} else {
rating_criteria_results[i] <- paste(part_id, "failed the rating criterion")
}
}
# Print the results
cat(rating_criteria_results, sep = "\n")
# Create lists to keep track of participants who passed or failed
passed_summary_criterion <- c()
failed_summary_criterion <- c()
for (part_id in participants) {
# Extract rows for the current participant
participant_data <- df.raw.merged[df.raw.merged$participant == part_id,]
# Filter out NA values from summary_skipped column
summary_skipped_non_na <- na.omit(participant_data$summary_skipped)
# Check if all non-NA values are 1
if(all(summary_skipped_non_na == 1)) {
# All non-NA values are 1, so participant failed the summary criterion
failed_summary_criterion <- c(failed_summary_criterion, part_id)
} else {
# There are values other than 1, so participant passed the summary criterion
passed_summary_criterion <- c(passed_summary_criterion, part_id)
}
}
# Print
if(length(failed_summary_criterion) > 0) {
cat(paste(failed_summary_criterion, collapse = ", "), "failed the summary criterion.\n")
}
if(length(passed_summary_criterion) > 0) {
cat(paste(passed_summary_criterion, collapse = ", "), "passed the summary criterion.\n")
}
# Calculate movement score with magnitude for each trial
df.raw.merged <- df.raw.merged %>%
rowwise() %>%
mutate(trial_movement_score_magnitude =
ifelse(slider_values[[1]][1] == 0, sum(abs(diff(unlist(slider_values)))), NA))
# Aggregate these scores for each participant
participant_movement_scores <- df.raw.merged %>%
group_by(participant) %>%
summarise(movement_score_all = sum(trial_movement_score_magnitude, na.rm = TRUE))
# Add the movement scores back to the df
df.raw.merged <- left_join(df.raw.merged, participant_movement_scores, by = "participant")
# Calculate mean and standard deviation for movement scores, identify outliers
mean_movement_score <- mean(participant_movement_scores$movement_score_all, na.rm = TRUE)
sd_movement_score <- sd(participant_movement_scores$movement_score_all, na.rm = TRUE)
cutoff_upper <- mean_movement_score + 3.5 * sd_movement_score
cutoff_lower <- mean_movement_score - 3.5 * sd_movement_score
outliers <- participant_movement_scores %>%
filter(movement_score_all < cutoff_lower | movement_score_all > cutoff_upper) %>%
pull(participant)
# Print participant IDs for those outside the ±3.5 SD range
cat("Participants outside the ±3.5 SD range:", paste(outliers, collapse = ", "), "\n")
#Save the organized data
# Convert list to string for slider values
df.raw.merged$slider_values <- sapply(df.raw.merged$slider_values,
function(x) paste(x, collapse = ","))
df.raw.merged$slider_values_rescaled <- sapply(df.raw.merged$slider_values_rescaled,
function(x) paste(x, collapse = ","))
output_file_path <- file.path(organized_data_path, "organized_data.csv")
write.csv(df.raw.merged, output_file_path, row.names = FALSE)
# Load the dataset created after calculating the semantic similarity scores
df.data <- read.csv(file.path(organized_data_path, "organized_data_semantic.csv"))
# Let's visualize the slider values across speech rates
df.slider <- df.data %>%
mutate(slider_values_rescaled = strsplit(slider_values_rescaled, ",")) %>%
mutate(slider_rescale_float = map(slider_values_rescaled, ~as.numeric(.x)))
df_long <- df.slider %>%
mutate(id = row_number()) %>%
unnest(slider_rescale_float) %>%
rename(slider_value = slider_rescale_float) %>%
group_by(id, speech_rate) %>%
mutate(index = row_number()) %>%
ungroup() %>%
select(-slider_values_rescaled)
# Set the x-axis limits
max_index <- max(df_long$index)
p_slider_per_rate <- ggplot(df_long, aes(x = index,
y = slider_value,
group = interaction(id),
color = as.factor(id))) +
geom_line(alpha = 0.5, size = 0.5) +
scale_x_continuous(limits = c(0, max_index), name = "Index of the Slider Value") +
scale_y_continuous(name = "Slider Value") +
facet_wrap(~ speech_rate, scales = 'free_x', ncol = 3) +
scale_color_manual(values = colorRampPalette(brewer.pal(12, "Paired"))
(length(unique(df_long$id)))) +
theme(legend.position = "none") +
labs(title = 'Slider Values by Speech Rate',
caption = "Each line represents the comprehension trajectory at different speech rates.
As the speech rate increases, comprehension scores seem to get lower."
)
# Make x-axis limits consistent across facets
p_slider_per_rate <- p_slider_per_rate + facet_wrap(~ speech_rate,
scales = 'free_x',
nrow = 2) +
theme(strip.text.x = element_text(size = 10))
print(p_slider_per_rate)
model <- lmer(trial_median_rescaled ~
sum_max_similarity +
likert_response +
multiple_choice_accuracy +
(1 | digit_span_score) +
(1 | digit_in_noise_score), data = df.data)
summary(model)
# Depict the likert scale and slider values for each speech rate. Their patterns should look quite similar based on the regression analysis
# Calculate the average  likert_response scores per speech_rate category
average_likert_scores <- df.data %>%
group_by(speech_rate) %>%
summarise(average_likert = mean(likert_response, na.rm = TRUE))
# Plotting the average likert scale across speech rates
p1 <- ggplot(average_likert_scores, aes(x = factor(speech_rate), y = average_likert)) +
geom_bar(stat = "identity", fill = "cornflowerblue") +
labs(x = "Speech Rate", y = "Likert Scores", title = "Average Likert Response
per Speech Rate") +
geom_text(aes(label = round(average_likert, 2)), vjust = -0.5, size = 3.5)
# Calculate the average trial_median_rescaled for each speech_rate category
average_trial_median <- df.data %>%
group_by(speech_rate) %>%
summarise(average_trial_median = mean(trial_median_rescaled, na.rm = TRUE))
# Plot
p2 <- ggplot(average_trial_median, aes(x = factor(speech_rate), y = average_trial_median,
fill = as.factor(speech_rate))) +
geom_bar(stat = "identity", position = "dodge") +
scale_fill_brewer(palette = "Pastel1", name = "Speech Rate") +
labs(x = "Speech Rate", y = "Real-Time Comprehension Scores",
title = "  Average of the Median
Real-Time Comprehension Scores
per Speech Rate") +
geom_text(aes(label = round(average_trial_median, 2)), vjust = -0.3,
position = position_dodge(width = 0.9), size = 3) +
theme(legend.position = "none")
# Arrange the plots side by side
combined_plot <- p1 + p2 + plot_layout(ncol = 2)
print(combined_plot)
# Calculate the average multiple_choice_accuracy scores per speech_rate category
average_scores <- df.data %>%
group_by(speech_rate) %>%
summarise(average_accuracy = mean(multiple_choice_accuracy, na.rm = TRUE))
# plot
ggplot(average_scores, aes(x = factor(speech_rate), y = average_accuracy)) +
geom_bar(stat = "identity", fill = "lightpink") +
labs(x = "Speech Rate",
y = "Average Multiple Choice Accuracy",
title = "Average Accuracy by Speech Rate") +
geom_text(aes(label = round(average_accuracy, 2)), vjust = -0.5, size = 3.5)
# Select trials with speech rate = 4
df_data_speech_rate_4 <- df.data %>%
filter(speech_rate == 4)
# Find out the max index number per participant to categorize last 50
max_index_numbers <- df_data_speech_rate_4 %>%
group_by(participant) %>%
summarise(max_index = max(index), .groups = "drop")
# Merge max_index_numbers with df_data_speech_rate_4
df_data_speech_rate_4 <- df_data_speech_rate_4 %>%
left_join(max_index_numbers, by = "participant")
# Categorize trials into first 50, mid 50, last 50
df_data_speech_rate_4 <- df_data_speech_rate_4 %>%
mutate(trial_group = case_when(
index <= 50 ~ "First 50",
index > 50 & index <= (max_index - 50) ~ "Mid 50",
index > (max_index - 50) ~ "Last 50"
))
# Calculate the average multiple_choice_accuracy for each trial group
average_accuracy <- df_data_speech_rate_4 %>%
group_by(trial_group) %>%
summarise(average_accuracy = mean(multiple_choice_accuracy, na.rm = TRUE),
.groups = "drop") %>%
mutate(trial_group = factor(trial_group,
levels = c("First 50", "Mid 50", "Last 50"))) # order
# Plot
ggplot(average_accuracy, aes(x = trial_group, y = average_accuracy, fill = trial_group)) +
geom_bar(stat = "identity") +
labs(x = "Trial Group", y = "Average Accuracy",
title = "Average Accuracy per Trial Group (Speech Rate = 4)") +
scale_fill_brewer(palette = "Pastel1") +
geom_text(aes(label = round(average_accuracy, 3)), vjust = -0.5, size = 3) +
theme(legend.position = "none")
model_trial <- lmer(trial_median_rescaled ~
sum_max_similarity +
likert_response +
multiple_choice_accuracy * index +  # Interaction between trial number and multiple_choice_accuracy
(1 | digit_span_score) +
(1 | digit_in_noise_score), data = df.data)
summary(model_trial)
# Compare the two models
comparison <- anova(model, model_trial)
print(comparison)
# Assuming df.data is already loaded and contains the variables of interest
average_similarity <- df.data %>%
group_by(speech_rate) %>%
summarise(average_similarity = mean(sum_max_similarity, na.rm = TRUE))
# Plot with bars in light green
ggplot(average_similarity, aes(x = factor(speech_rate), y = average_similarity, fill = as.factor(speech_rate))) +
geom_bar(stat = "identity", position = "dodge", fill = "darkseagreen1") +
labs(x = "Speech Rate", y = "Average Sum Max Similarity",
title = "Average Sum Max Similarity by Speech Rate") +
geom_text(aes(label = round(average_similarity, 2)),
vjust = -0.3, position = position_dodge(width = 0.9), size = 3) +
theme(legend.position = "none")
#What about the number of words they reported regardless of the semantic similarity of the words?
# Calculate the number of words
df.data <- df.data %>%
mutate(word_count = str_count(textbox.text_corrected, "\\S+") + 1)
# Aggregate data by speech rate
aggregated_data <- df.data %>%
group_by(speech_rate) %>%
summarize(avg_word_count = mean(word_count, na.rm = TRUE),
.groups = 'drop')
# Plot
ggplot(aggregated_data, aes(x = as.factor(speech_rate), y = avg_word_count,
fill = as.factor(speech_rate))) +
geom_bar(stat = "identity" , position = "dodge", fill = "darkseagreen3") +
geom_text(aes(label = sprintf("%.2f", avg_word_count)), vjust = -0.5, color = "black") +
labs(title = "Average Number of Words Reported Across Speech Rates",
x = "Speech Rate",
y = "Average Word Count",
fill = "Speech Rate") +
theme(legend.position = "none")
# check the model again
model
